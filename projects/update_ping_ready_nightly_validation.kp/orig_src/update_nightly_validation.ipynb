{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: update ping validation on Nightly\n",
    "authors:\n",
    "- dexter\n",
    "tags:\n",
    "- firefox\n",
    "- update\n",
    "- latency\n",
    "created_at: 2016-08-14\n",
    "updated_at: 2016-08-14\n",
    "tldr: This notebook verifies that the `update` ping with `reason = ready` behaves as expected on Nightly.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate 'update' ping submissions on Nightly (`reason = ready`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis validates the `update` ping with `reason = ready`, which was introduced in [bug 1120372](https://bugzilla.mozilla.org/show_bug.cgi?id=1120372) and should be sent every time an update is downloaded and ready to be applied. We are going to verify that:\n",
    "\n",
    "- the ping is received within a reasonable time after being created;\n",
    "- we receive one ping per update;\n",
    "- that the payload looks ok;\n",
    "- check if the volume of update pings is within the expected range by cross-checking it with the main pings;\n",
    "- that we don't receive many duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ujson as json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.plotly as py\n",
    "import IPython\n",
    "\n",
    "from plotly.graph_objs import *\n",
    "from moztelemetry import get_pings_properties, get_one_ping_per_client\n",
    "from moztelemetry.dataset import Dataset\n",
    "from datetime import datetime, timedelta\n",
    "from email.utils import parsedate_tz, mktime_tz, formatdate\n",
    "\n",
    "%matplotlib inline\n",
    "IPython.core.pylabtools.figsize(16, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `update` ping landed on the Nightly channel on the 27th of July, 2017. However, shortly after we had merge day. Let's try to get the first full-week of data after the merge week up to today: 6th of August to the 12th of August, 2017. Restrict to the data coming from the Nightly builds after the day the ping landed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "update_pings = Dataset.from_source(\"telemetry\") \\\n",
    "    .where(docType=\"OTHER\") \\\n",
    "    .where(appUpdateChannel=\"nightly\") \\\n",
    "    .where(submissionDate=lambda x: \"20170806\" <= x < \"20170813\") \\\n",
    "    .where(appBuildId=lambda x: \"20170728\" <= x < \"20170813\") \\\n",
    "    .records(sc, sample=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "update_pings = update_pings.filter(lambda p: p.get(\"type\") == \"update\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some misc functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pct(a, b):\n",
    "    return 100.0 * a / b\n",
    "\n",
    "def dedupe(pings, duping_key):\n",
    "    return pings\\\n",
    "            .map(lambda p: (p[duping_key], p))\\\n",
    "            .reduceByKey(lambda a, b: a if a[\"meta/Timestamp\"] < b[\"meta/Timestamp\"] else b)\\\n",
    "            .map(lambda pair: pair[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misc functions to plot the CDF of the submission delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_DELAY_S = 60 * 60 * 96.0\n",
    "HOUR_IN_S = 60 * 60.0\n",
    "\n",
    "def setup_plot(title, max_x, area_border_x=0.1, area_border_y=0.1):\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Delay (hours)\")\n",
    "    plt.ylabel(\"% of pings\")\n",
    "\n",
    "    plt.xticks(range(0, int(max_x) + 1, 2))\n",
    "    plt.yticks(map(lambda y: y / 20.0, range(0, 21, 1)))\n",
    "\n",
    "    plt.ylim(0.0 - area_border_y, 1.0 + area_border_y)\n",
    "    plt.xlim(0.0 - area_border_x, max_x + area_border_x)\n",
    "\n",
    "    plt.grid(True)\n",
    "\n",
    "def plot_cdf(data, **kwargs):\n",
    "    sortd = np.sort(data)\n",
    "    ys = np.arange(len(sortd))/float(len(sortd))\n",
    "\n",
    "    plt.plot(sortd, ys, **kwargs)\n",
    "    \n",
    "def calculate_submission_delay(p):\n",
    "    created = datetime.fromtimestamp(p[\"meta/creationTimestamp\"] / 1000.0 / 1000.0 / 1000.0)\n",
    "    received = datetime.fromtimestamp(p[\"meta/Timestamp\"] / 1000.0 / 1000.0 / 1000.0)\n",
    "    sent = datetime.fromtimestamp(mktime_tz(parsedate_tz(p[\"meta/Date\"]))) if p[\"meta/Date\"] is not None else received\n",
    "    clock_skew = received - sent\n",
    "\n",
    "    return (received - created - clock_skew).total_seconds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the ping payload\n",
    "Check that the payload section contains the right entries with consistent values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subset = get_pings_properties(update_pings, [\"id\",\n",
    "                                             \"clientId\",\n",
    "                                             \"meta/creationTimestamp\",\n",
    "                                             \"meta/Date\",\n",
    "                                             \"meta/Timestamp\",\n",
    "                                             \"application/buildId\",\n",
    "                                             \"application/channel\",\n",
    "                                             \"application/version\",\n",
    "                                             \"environment/system/os/name\",\n",
    "                                             \"payload/reason\",\n",
    "                                             \"payload/targetBuildId\",\n",
    "                                             \"payload/targetChannel\",\n",
    "                                             \"payload/targetVersion\"])\n",
    "\n",
    "ping_count = subset.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantify the percentage of duplicate pings we're receiving. We don't expect this value to be greater than ~1%, which is the amount we usually get from `main` and `crash`: as a rule of thumb, we threat anything less than 1% as *probably* well behaving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deduped_subset = dedupe(subset, \"id\")\n",
    "deduped_count = deduped_subset.count()\n",
    "print(\"Percentage of duplicate pings: {:.3f}\".format(100.0 - pct(deduped_count, ping_count)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The percentage of duplicate pings is within the expected range. Move on and verify the payload of the `update` pings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def validate_update_payload(p):\n",
    "    PAYLOAD_KEYS = [\n",
    "        \"payload/reason\",\n",
    "        \"payload/targetBuildId\",\n",
    "        \"payload/targetChannel\",\n",
    "        \"payload/targetVersion\"\n",
    "    ]\n",
    "\n",
    "    # All the payload keys needs to be strings.\n",
    "    for k in PAYLOAD_KEYS:\n",
    "        if not isinstance(p.get(k), basestring):\n",
    "            return (\"'{}' is not a string\".format(k), 1)\n",
    "        \n",
    "    # We only expect \"reason\" = ready.\n",
    "    if p.get(\"payload/reason\") != \"ready\":\n",
    "        return (\"Unexpected 'reason' {}\".format(p.get(\"payload/reason\"), 1))\n",
    "        \n",
    "    # For Nightly, the target channel should be the same as the\n",
    "    # application channel.\n",
    "    if p.get(\"payload/targetChannel\") != p.get(\"application/channel\"):\n",
    "        return (\"Target channel mismatch: expected {} got {}\"\\\n",
    "                .format(p.get(\"payload/targetChannel\"), p.get(\"application/channel\")), 1)\n",
    "                \n",
    "    # The target buildId must be greater than the application build id.\n",
    "    if p.get(\"payload/targetBuildId\") <= p.get(\"application/buildId\"):\n",
    "        return (\"Target buildId mismatch: {} must be more recent than {}\"\\\n",
    "                .format(p.get(\"payload/targetBuildId\"), p.get(\"application/buildId\")), 1)\n",
    "    \n",
    "    return (\"Ok\", 1)\n",
    "\n",
    "validation_results = deduped_subset.map(validate_update_payload).countByKey()\n",
    "for k, v in sorted(validation_results.iteritems()):\n",
    "    print(\"{}:\\t{:.3f}%\".format(k, pct(v, ping_count)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vast majority of the data in the payload seems reasonable (99.71%).\n",
    "\n",
    "However, a handful of `update` pings are reporting a `targetBuildId` which is older than the current build reported by the ping's environment: this is unexpected, as the the target build id must be always greater than the current one. After discussing this with the *update team*, it seems like this could either be due to Nigthly channel weirdness or to the customization applied by the [CCK tool](https://mike.kaply.com/cck2/). Additionally, some pings are reporting a `targetChannel` different than the one in the environment: this is definitely due to the CCK tool, given the *cck* entry in the channel name. These issues do not represent a problem, as most of the data is correct and their volume is fairly low.\n",
    "\n",
    "## Check that we receive one ping per client and target update\n",
    "For each ping, build a key with the client id and the target update details. Since we expect to have exactly one ping for each update bundle marked as *ready*, we don't expect duplicate keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "update_dupes = deduped_subset.map(lambda p: ((p.get(\"clientId\"),\n",
    "                                              p.get(\"payload/targetChannel\"),\n",
    "                                              p.get(\"payload/targetVersion\"),\n",
    "                                              p.get(\"payload/targetBuildId\")), 1)).countByKey()\n",
    "\n",
    "print(\"Percentage of pings related to the same update (for the same client):\\t{:.3f}%\"\\\n",
    "      .format(pct(sum([v for v in update_dupes.values() if v > 1]), deduped_count)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're receiving `update` pings with different `documentId` related to the same target update bundle, for a few clients. One possible reason for this could be users having multiple copies of Firefox installed on their machine. Let's see if that's the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clientIds_sending_dupes = [k[0] for k, v in update_dupes.iteritems() if v > 1]\n",
    "\n",
    "def check_same_original_build(ping_list):\n",
    "    # Build a \"unique\" identifier for the build by\n",
    "    # concatenating the buildId, channel and version.\n",
    "    unique_build_ids = [\n",
    "        \"{}{}{}\".format(p.get(\"application/buildId\"), p.get(\"application/channel\"), p.get(\"application/version\"))\\\n",
    "        for p in ping_list[1]\n",
    "    ]\n",
    "    \n",
    "    # Remove the duplicates and return True if all the pings came\n",
    "    # from the same build.\n",
    "    return len(set(unique_build_ids)) < 2\n",
    "    \n",
    "# Count how many duplicates come from the same builds and how many come from\n",
    "# different original builds.\n",
    "original_builds_same =\\\n",
    "    deduped_subset.filter(lambda p: p.get(\"clientId\") in clientIds_sending_dupes)\\\n",
    "                  .map(lambda p: ((p.get(\"clientId\"),\n",
    "                                   p.get(\"payload/targetChannel\"),\n",
    "                                   p.get(\"payload/targetVersion\"),\n",
    "                                   p.get(\"payload/targetBuildId\")), [p]))\\\n",
    "                  .reduceByKey(lambda a, b: a + b)\\\n",
    "                  .filter(lambda p: len(p[1]) > 1)\\\n",
    "                  .map(check_same_original_build).countByValue()\n",
    "                    \n",
    "print(\"Original builds are identical:\\t{:.3f}%\"\\\n",
    "      .format(pct(original_builds_same.get(True), sum(original_builds_same.values()))))\n",
    "print(\"Original builds are different:\\t{:.3f}%\"\\\n",
    "      .format(pct(original_builds_same.get(False), sum(original_builds_same.values()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data shows that the `update` pings with the same target version are not necessarily coming from the same profile being used on different Firefox builds/installation. After discussing this with the *update team*, it turns out that this can be explained by updates failing to apply: for certain classes of errors, we download the update blob again and thus send a new `update` ping with the same target version. This problem shows up in the [update orphaning](https://telemetry.mozilla.org/update-orphaning/) dashboard as well but, unfortunately, it only reports Release data.\n",
    "\n",
    "## Validate the submission delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delays = deduped_subset.map(lambda p: calculate_submission_delay(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "setup_plot(\"'update' ('ready') ping submission delay CDF\",\n",
    "           MAX_DELAY_S / HOUR_IN_S, area_border_x=1.0)\n",
    "\n",
    "plot_cdf(delays\\\n",
    "         .map(lambda d: d / HOUR_IN_S if d < MAX_DELAY_S else MAX_DELAY_S / HOUR_IN_S)\\\n",
    "         .collect(), label=\"CDF\", linestyle=\"solid\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all of the `update` ping are submitted within an hour from the update being ready.\n",
    "\n",
    "## Make sure that the volume of incoming `update` pings is reasonable\n",
    "This is a tricky one. The `update` ping with `reason = \"ready\"` is sent as soon as an update package is downloaded, verified and deemed ready to be applied. However, nothing guarantees that the update is immediately (or ever) applied. To check if the volume of `update` pings is in the ballpark, we can:\n",
    "\n",
    "1. Get a list of client ids for a specific target update build id '20170809xxxxxx'.\n",
    "2. Get the `main-ping` for that version of Firefox.\n",
    "3. Check how many clients from the list at (1) are in the list at (2).\n",
    "\n",
    "**Step 1** - Get the list of client ids updating to build '20170809xxxxxx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TARGET_BUILDID_MIN = '20170809000000'\n",
    "TARGET_BUILDID_MAX = '20170809999999'\n",
    "\n",
    "update_candidates =\\\n",
    "    deduped_subset.filter(lambda p: TARGET_BUILDID_MIN <= p.get(\"payload/targetBuildId\") <= TARGET_BUILDID_MAX)\n",
    "update_candidates_clientIds = dedupe(update_candidates, \"clientId\").map(lambda p: p.get(\"clientId\"))\n",
    "candidates_count = update_candidates_clientIds.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2** - Get the `main-ping` from that Nightly build and extract the list of client ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "updated_main_pings = Dataset.from_source(\"telemetry\") \\\n",
    "    .where(docType=\"main\") \\\n",
    "    .where(appUpdateChannel=\"nightly\") \\\n",
    "    .where(submissionDate=lambda x: \"20170809\" <= x < \"20170816\") \\\n",
    "    .where(appBuildId=lambda x: TARGET_BUILDID_MIN <= x <= TARGET_BUILDID_MAX) \\\n",
    "    .records(sc, sample=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just need the client ids and a few other fields to dedupe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subset_main = get_pings_properties(updated_main_pings, [\"id\",\n",
    "                                                        \"clientId\",\n",
    "                                                        \"meta/Timestamp\",\n",
    "                                                        \"application/buildId\",\n",
    "                                                        \"application/channel\",\n",
    "                                                        \"application/version\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by deduping by document id. After that, only get a single ping per client and extract the list of client ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deduped_main = dedupe(subset_main, \"id\")\n",
    "updated_clientIds = dedupe(deduped_main, \"clientId\").map(lambda p: p.get(\"clientId\"))\n",
    "updated_count = updated_clientIds.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3** - Count how many clients that were meant to update actually updated in the following 7 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matching_clientIds = update_candidates_clientIds.intersection(updated_clientIds)\n",
    "matching_count = matching_clientIds.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"{:.3f}% of the clients that sent the update ping updated to the newer Nightly build within a week.\"\\\n",
    "      .format(pct(matching_count, candidates_count)))\n",
    "print(\"{:.3f}% of the clients that were seen on the newer Nightly build sent an update ping.\"\\\n",
    "      .format(pct(candidates_count, updated_count)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roughly 80% of the clients that were seen in the new Nightly build also sent the update ping. The 95%ile of the `main-ping` data from Nightly 57 reaches us with a 9.4 hour delay (see [here](https://sql.telemetry.mozilla.org/queries/6576)), so most of the data should be in already. This could be due to a few reasons:\n",
    "\n",
    "- some users are disabling automatic updates and no `update` ping is sent [in that case](https://bugzilla.mozilla.org/show_bug.cgi?id=1386619) if an update is manually triggered;\n",
    "- some users are doing pave-over installs, by re-installing Firefox through the installer rather than relying on the update system;\n",
    "- another unkown edge case in the client, that was not documented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}