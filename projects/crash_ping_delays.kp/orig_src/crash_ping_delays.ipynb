{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Crash Ping Submission Delays by Channel\"\n",
    "authors:\n",
    "- chutten\n",
    "tags:\n",
    "- crash ping\n",
    "- delay\n",
    "created_at: 2017-01-26\n",
    "updated_at: 2017-01-26\n",
    "tldr: How long does it take before we get crash pings from users in each channel?\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crash Ping Submission Delays by Channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is follow-up analysis to the [Main Ping Submission and Recording Delays by Channel](https://github.com/mozilla/mozilla-reports/blob/master/projects/ping_delays.kp/knowledge.md) analysis previously performed.\n",
    "\n",
    "Specifically, I'm investigating what typical values of \"submission delay\" might be for \"crash\" pings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ujson as json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.plotly as py\n",
    "import IPython\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from email.utils import parsedate_tz, mktime_tz, formatdate\n",
    "\n",
    "from plotly.graph_objs import *\n",
    "from moztelemetry import get_pings_properties, get_one_ping_per_client\n",
    "from moztelemetry.dataset import Dataset\n",
    "\n",
    "%matplotlib inline\n",
    "IPython.core.pylabtools.figsize(16, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the \"crash\" ping. I am assuming that the recording delay is well under one second for crash events, as by their nature they are either recorded immediately or not at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at Jan 10, 2017 as per the previous analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pings = Dataset.from_source(\"telemetry\") \\\n",
    "    .where(docType='crash') \\\n",
    "    .where(submissionDate=\"20170110\") \\\n",
    "    .records(sc, sample=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look at delays, we need to look at times. There are a lot of times, and they are recorded relative to different clocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`creationDate`** - The time the Telemetry code in Firefox created the ping, according to the client's clock, expressed as an ISO string. **`meta/creationTimestamp`** is the same time, but expressed in nanoseconds since the epoch.\n",
    "\n",
    "**`meta/Date`** - The time the Telemetry code in Firefox sent the ping to the server, according to the client's clock, expressed as a Date string conforming to [RFC 7231](https://tools.ietf.org/html/rfc7231#section-7.1.1.1).\n",
    "\n",
    "**`meta/Timestamp`** - The time the ping was received by the server, according to the server's\n",
    "clock, expressed in nanoseconds since the epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subset = get_pings_properties(pings, [\"application/channel\",\n",
    "                                      \"creationDate\",\n",
    "                                      \"meta/creationTimestamp\",\n",
    "                                      \"meta/Date\",\n",
    "                                      \"meta/Timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = subset.take(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick normalization: ditch any ping that doesn't have a creationTimestamp or Timestamp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prev_count = subset.count()\n",
    "subset = subset.filter(lambda p:\\\n",
    "                       p[\"meta/Timestamp\"] is not None\\\n",
    "                       and p[\"meta/creationTimestamp\"] is not None)\n",
    "filtered_count = subset.count()\n",
    "\n",
    "\"{:.2f}% ({} of {}) pings were filtered\".format((prev_count - filtered_count) / prev_count, prev_count - filtered_count, prev_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be plotting Cumulative Distribution Functions today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_DELAY_S = 60 * 60 * 96.0\n",
    "HOUR_IN_S = 60 * 60.0\n",
    "CHANNELS = ['release', 'beta', 'aurora', 'nightly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_plot(title, max_x):\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Delay (hours)\")\n",
    "    plt.ylabel(\"% of pings\")\n",
    "\n",
    "    plt.xticks(range(0, int(max_x) + 1, 2))\n",
    "    plt.yticks(map(lambda y: y / 20.0, range(0, 21, 1)))\n",
    "\n",
    "    plt.ylim(0.0, 1.0)\n",
    "    plt.xlim(0.0, max_x)\n",
    "\n",
    "    plt.grid(True)\n",
    "\n",
    "def plot_cdf(data):\n",
    "    sortd = np.sort(data)\n",
    "    ys = np.arange(len(sortd))/float(len(sortd))\n",
    "\n",
    "    plt.plot(sortd, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_submission_delay(p):\n",
    "    created = datetime.fromtimestamp(p[\"meta/creationTimestamp\"] / 1000.0 / 1000.0 / 1000.0)\n",
    "    received = datetime.fromtimestamp(p[\"meta/Timestamp\"] / 1000.0 / 1000.0 / 1000.0)\n",
    "    sent = datetime.fromtimestamp(mktime_tz(parsedate_tz(p[\"meta/Date\"]))) if p[\"meta/Date\"] is not None else received\n",
    "    clock_skew = received - sent\n",
    "    \n",
    "    submission_delay = (received - created - clock_skew).total_seconds()\n",
    "    return submission_delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delay_by_chan = subset.map(lambda p: (p[\"application/channel\"], calculate_submission_delay(p)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission Delay\n",
    "\n",
    "**Submission Delay** is the delay between the data being recorded on the client and it being received by our infrastructure. It is thought to be dominated by the length of time Firefox isn't open on a client's computer, though retransmission attempts and throttling can also contribute.\n",
    "\n",
    "Here we run into a problem with **clock skew**. Clients' clocks aren't guaranteed to align with our server's clock, so we cannot necessarily compare the two. Luckily, with [bug 1144778](https://bugzilla.mozilla.org/show_bug.cgi?id=1144778) we introduced an HTTP `Date` header which tells us what time the client's clock thinks it is when it is sending the data. Coupled with the `Timestamp` field recorded which is what time the server's clock thinks it is when it receives the data, we can subtract the more egregious examples of clock skew and get values that are closer to reality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "setup_plot(\"Submission Delay CDF\", MAX_DELAY_S / HOUR_IN_S)\n",
    "\n",
    "for chan in CHANNELS:\n",
    "    plot_cdf(delay_by_chan\\\n",
    "             .filter(lambda d: d[0] == chan)\\\n",
    "             .map(lambda d: d[1] / HOUR_IN_S if d[1] < MAX_DELAY_S else MAX_DELAY_S / HOUR_IN_S)\\\n",
    "             .collect())\n",
    "    \n",
    "plt.legend(CHANNELS, loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many crash pings are submitted with much lower delays than \"main\" pings.\n",
    "\n",
    "However, especially for the release channel, the last 5% of crash pings take more than 96 hours, the same as for \"main\" pings.\n",
    "\n",
    "The nightly channel is an interesting abberation compared to the others in that it starts as the slowest submitter, but at about 24 hours it has caught up with the fastest. My guess is that nightly users might be more prone to just let a crashed browser die and leave it until tomorrow to restart.\n",
    "\n",
    "Using information from both types of pings in order to generate a single statistic (like \"crash rates per thousand usage hours\") will have problems wherever the lines do not line up. Until about 48 hours' delay, we have received too many \"crash\" pings and too few \"main\" pings for the counts to line up and provide us with a sensible rate."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}