---
title: "Webrender Release 66 experiment"
author: "tdsmith"
date: '2019-04-17'
output:
  html_document:
    md_extensions: +emoji
    toc: true
    toc_float: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.height=3, fig.width=8)

library(broom)
library(boot)
library(dplyr)
library(feather)
library(ggplot2)
library(readr)
library(RSQLite)
library(tidyr)

# https://dbc-caf9527b-e073.cloud.databricks.com/#notebook/94118/command/94218
db = DBI::dbConnect(SQLite(), "20190417-wr66.sqlite")
per_user = tbl(db, "per_user") %>% collect
slow_stats = tbl(db, "slow_stats") %>% collect
.crashes = tbl(db, "crashes") %>% collect
crashes_per_process = tbl(db, "crashes_per_process") %>% collect

DBI::dbDisconnect(db)

# https://dbc-caf9527b-e073.cloud.databricks.com/#notebook/103517/command/103989
engagement = read_feather("20190419-wr66_enagement.feather")

retention = read_csv("branch,weeks_since_enrollment,n,week_0,fraction
default,0,131593,131593,1.0
default,1,122244,131593,0.9289551875859658
default,2,104960,131593,0.7976108151649404
enabled,0,132524,132524,1.0
enabled,1,122770,132524,0.9263982373004135
enabled,2,105741,132524,0.7979007575986237
")

enroll_db = DBI::dbConnect(SQLite(), "20190422_wr66-enrollment.sqlite")
enroll_daily = tbl(enroll_db, "enroll_daily") %>% collect
unenroll_daily = tbl(enroll_db, "unenroll_daily") %>% collect
DBI::dbDisconnect(enroll_db)

N_BOOT = 400

perf_medians = per_user %>%
  group_by(branch, metric) %>%
  summarize(
    user_median=median(mean, na.rm=TRUE)
  )

transform_branch = function(df) {
  mutate(df, branch=factor(branch, c("default", "enabled"), c("Gecko", "WebRender")))
}
```

Performance endpoints:

Probe | Success? | Criterion | Actual
----- | -------- | --------- | ------
`COMPOSITE_TIME` | :white_check_mark: | Median per-user fraction of slow frames < 0.5% (absolute) | 0.16% slow
`CONTENT_FRAME_TIME_VSYNC` | :white_check_mark: | ≤ 5% regression in median of per-user fraction of slow events | 1.7-3.9% regression
`CONTENT_FULL_PAINT_TIME` | :white_check_mark: | ≤ 5% regression in median fraction of slow paints (> 16 ms) | 44.8-46.4% improvement
`CONTENT_FULL_PAINT_TIME` | :x: | ≤ 5% regression in median of per-user means | 8.7-9.9% regression
`FX_PAGE_LOAD_MS_2` | :white_check_mark: | ≤ 5% regression in median of per-user means | No difference
`FX_TAB_SWITCH_COMPOSITE_E10S_MS` | :white_check_mark: | ≤ 5% regression in median of per-user means | 2.1-2.7% improvement

Stability endpoints:

Endpoint | Success | Criterion | Actual
-------- | ------- | --------- | ------
Overall crash reports | :x: | ≤ 5% increase in crash rate | 6% increase in crash rate
OOM crash reports | :white_check_mark: | ≤ 5% increase in crash rate | 20% decrease in OOM crashes
`CANVAS_WEBGL_SUCCESS` | :white_check_mark: | ≤ 5% regression in median of fraction "True" per user | No difference
`DEVICE_RESET_REASON` | :white_check_mark: | ≤ 5% increase in reset rate | 70% decrease in device resets

The higher crash rate in the WebRender branch is attributable to an increase in the rate of GPU process crashes.
Main and content process crash rates fell.

Retention and engagement metrics were not strongly affected.

# Introduction

[WebRender] is a new technology for getting webpages onto the screen using a GPU.
In [this experiment][experimenter], we enabled WebRender for users in the Firefox 66 release channel
running Windows 10 with certain GPU chipsets.

We have been running a [separate ongoing experiment][dashboard] in the beta and nightly channels to guide development,
observing how performance changes on a build-by-build basis. This report does not describe that work.

[dashboard]: https://metrics.mozilla.com/webrender/
[experimenter]: https://experimenter.services.mozilla.com/experiments/webrender-performance-66/
[WebRender]: https://hacks.mozilla.org/2017/10/the-whole-web-at-maximum-fps-how-webrender-gets-rid-of-jank/

# Results

## Performance

Before computing results for performance endpoints,
user sessions were filtered to ensure that
the compositor for the telmetry session matched the enrolled branch.
The first telemetry session after a user enrolled was dropped for users in both branches,
because the user needs to restart the browser after enrolling for WebRender to be enabled.
(The enrollment session was chosen by identifying the session containing the lowest `profile_subsession_counter` for each `client_id`.)
Users who unenrolled from the experiment were excluded.

This avoids a minimizing bias that could result from contaminating the results for the treatment branch
with results from users that were not exposed to the treatment.
The approach may overestimate the actual effect of WebRender on the population
if a non-random set of users (e.g. users with poor performance)
were more likely to unenroll from the experiment,
but this is unlikely because unenrollments were rare,
and balanced between the experiment and control branches (see "Enrollment" below)


### Continuous endpoints

```{r summarize_perf}
summarize_perf = function(df, var) {
  mystat = function(data, indices) {
    sample = data[indices,]
    median(sample[sample$branch == "enabled",][[var]], na.rm=TRUE) / median(sample[sample$branch == "default",][[var]], na.rm=TRUE)
  }

  df %>%
    boot(mystat, N_BOOT, strata=factor(df$branch), parallel="multicore", ncpus=4) %>%
    tidy(conf.int=TRUE, conf.method="basic") * 100
}

perf_summary = per_user %>%
  filter(!is.na(mean), metric != "content_frame_time_vsync", metric != "composite_time", metric != "webgl_success") %>%
  group_by(metric) %>%
  do(summarize_perf(., "mean"))

perf_summary %>%
  select(
    Metric=metric,
    `Median per-user mean, as WR % of Gecko`=statistic,
    `95% CI (low)`=conf.low,
    `95% CI (high)`=conf.high
  ) %>%
  knitr::kable(format.args=list(digits=3, nsmall=2))
```

#### Content paint time

WebRender users tended to have a somewhat higher average CONTENT_FULL_PAINT_TIME,
though WebRender users were less likely to have slow (> 16 ms) events (below).

```{r content_full_paint_time_cont_cdf, warning=FALSE}
per_user %>%
  filter(metric == "content_full_paint_time") %>%
  mutate(branch=factor(branch, c("enabled", "default"), c("WebRender", "Gecko"))) %>%
  ggplot(aes(mean, color=branch)) +
    geom_density(n=2048) +
    scale_x_continuous(limits=c(0, 100)) +
    coord_cartesian(xlim=c(0, 20)) +
    scale_color_discrete("Branch") +
    labs(x="Per-user average CONTENT_FULL_PAINT_TIME (ms)", title="Distribution of CONTENT_FULL_PAINT_TIME")
```

#### Page load time

The per-user-mean page load time distributions were essentially identical between WebRender and Gecko users.

```{r page_load_time_time_cont_cdf, warning=FALSE}
per_user %>%
  filter(metric == "page_load_ms") %>%
  mutate(branch=factor(branch, c("enabled", "default"), c("WebRender", "Gecko"))) %>%
  ggplot(aes(mean, color=branch)) +
    geom_density(n=2048) +
    scale_x_continuous(limits=c(0, 40000)) +
    coord_cartesian(xlim=c(0, 10000)) +
    scale_color_discrete("Branch") +
    labs(x="Per-user average page load time (ms)", title="Distribution of page load time")
```

#### Tab switch time

The median per-user average tab switch was slightly faster with WebRender.
The fastest tab switches took longer with WebRender enabled, but the slowest tab switches took less time.

```{r tab_switch_time_cont_cdf, warning=FALSE}
per_user %>%
  filter(metric == "tab_switch_composite", !is.na(mean)) %>%
  mutate(branch=factor(branch, c("enabled", "default"), c("WebRender", "Gecko"))) %>%
  ggplot(aes(mean, color=branch)) +
    geom_density(n=8192) +
    scale_x_continuous(limits=c(0, 1000)) +
    coord_cartesian(xlim=c(0, 250)) +
    scale_color_discrete("Branch") +
    labs(x="Per-user average tab switch (ms)", title="Distribution of page load time")
```

### Thresholded absolute endpoints (composite time)

The criterion for `COMPOSITE_TIME` was that the median per-user slow fraction should be < 0.5%.

```{r composite_time_cdf}
slow_stats %>%
  filter(metric == "composite_time") %>%
  mutate(branch=factor(branch, c("enabled", "default"), c("WebRender", "Gecko"))) %>%
  ggplot(aes(fraction_exceeding, color=branch)) +
    stat_ecdf() +
    scale_x_continuous(labels=scales::percent) +
    coord_cartesian(xlim=c(0, 0.1)) +
    geom_vline(xintercept=0.005) +
    scale_color_discrete("Branch") +
    annotate("text", x=0.006, y=0.5, label="0.05% slow events", hjust=0) +
    labs(x="Percent of composites that are slow", y="Fraction of users ≤ x", title="Distribution of per-user slow composite fraction")
```

The median fraction of slow composites is much higher in the WebRender branch compared to the Gecko branch,
but lower than the 0.5% threshold:

```{r composite_time_bootstrap}
summarize_composite_time = function(df) {
  mystat = function(data, indices) {
    sample = data[indices,]
    c(
      WebRender=median(sample[sample$branch == "enabled",]$fraction_exceeding, na.rm=TRUE),
      Gecko=median(sample[sample$branch == "default",]$fraction_exceeding, na.rm=TRUE)
    )
  }

  df %>%
    boot(mystat, N_BOOT, strata=factor(df$branch), parallel="multicore", ncpus=4) %>%
    tidy(conf.int=TRUE, conf.method="basic")
}

composite_time_summary = slow_stats %>%
  filter(metric == "composite_time") %>%
  summarize_composite_time

composite_time_summary %>%
  mutate(statistic=statistic*100, conf.low=conf.low*100, conf.high=conf.high*100) %>%
  select(
    Branch=term,
    `Median per-user slow composites (percent)`=statistic,
    `95% CI (low)`=conf.low,
    `95$ CI (high)`=conf.high
  ) %>%
  knitr::kable(format.args=list(digits=3, nsmall=2))
```

### Thresholded comparative endpoints

```{r summarize_slow}
slow_summary = slow_stats %>%
  filter(!is.na(fraction_exceeding), metric != "composite_time") %>%
  group_by(metric, threshold) %>%
  do(summarize_perf(., "fraction_exceeding"))

slow_summary %>%
  ungroup %>%
  mutate(Metric=sprintf("%s (> %d)", metric, threshold)) %>%
  select(
    Metric,
    `Median per-user fraction, as WR % of Gecko`=statistic,
    `95% CI (low)`=conf.low,
    `95% CI (high)`=conf.high
  ) %>%
  knitr::kable(format.args=list(digits=3, nsmall=2))
```

#### Content frame time

The median WebRender and Gecko user experienced very similar fractions of slow CONTENT_FRAME_TIME_VSYNCs (> 200% vsync).

The fraction of slow frames was somewhat higher for the slowest half of WebRender users than it was for the slowest half of Gecko users.

```{r content_frame_paint_time_cdf}
slow_stats %>%
  filter(metric == "content_frame_time_vsync") %>%
  mutate(branch=factor(branch, c("enabled", "default"), c("WebRender", "Gecko"))) %>%
  ggplot(aes(fraction_exceeding, color=branch)) +
    stat_ecdf() +
    scale_x_continuous(labels=scales::percent) +
    coord_cartesian(xlim=c(0, 0.3)) +
    scale_color_discrete("Branch") +
    labs(x="Percent of frames that are slow", y="Fraction of users ≤ x", title="Distribution of per-user slow frame fraction")
```

#### Content paint time

The median WebRender user experienced considerably fewer slow paints (> 16 ms) than the median Gecko user.

The worst-performing 20% of users in the WebRender and Gecko branches had similar slow paint fractions.

```{r content_full_paint_time_cdf}
slow_stats %>%
  filter(metric == "content_full_paint_time") %>%
  mutate(branch=factor(branch, c("enabled", "default"), c("WebRender", "Gecko"))) %>%
  ggplot(aes(fraction_exceeding, color=branch)) +
    stat_ecdf() +
    scale_x_continuous(labels=scales::percent) +
    coord_cartesian(xlim=c(0, 0.2)) +
    scale_color_discrete("Branch") +
    labs(x="Percent of paints that are slow", y="Fraction of users ≤ x", title="Distribution of per-user slow paint fraction")
```

## Stability

Sessions were filtered for stability in the same manner as for performance.

```{r annotate_crash_stats}
poisson_ci = function(crash_count) {
  tibble(
    ymin=qchisq(0.025, 2*crash_count)/2,
    y=crash_count,
    ymax=qchisq(0.975, 2*(crash_count+1))/2
  )
}

crashes = .crashes %>%
  gather("crash", "count", total_crashes, oom_crashes, device_reset_reason_total) %>%
  group_by(branch, usage_hours, crash) %>%
  do(poisson_ci(.$count)) %>%
  ungroup
```

Despite a clear increase in GPU process crashes,
the overall crash rate was only slightly higher because
the number of main and content process crashes fell.

### Overall crash reports

```{r total_crashes}
crashes %>%
  filter(crash == "total_crashes") %>%
  mutate(branch=factor(branch, c("default", "enabled"), c("Gecko", "WebRender"))) %>%
  ggplot(aes(branch, y/usage_hours*1000, ymin=ymin/usage_hours*1000, ymax=ymax/usage_hours*1000)) +
    geom_col(width=0.3) +
    geom_errorbar(width=0.05) +
    labs(title="All crashes: crashes per 1000 usage hours", y="Crashes / 1000 hr", x="Branch") +
    geom_text(aes(label=format(y/usage_hours*1000, digits=3)), nudge_y=0.15) +
    ylim(0, 3)
```

### Per-process crash reports

```{r process_crashes}
crashes_per_process %>%
  filter(process != "rdd") %>%
  select(branch, process, total_crashes, usage_hours) %>%
  group_by_all() %>%
  do(poisson_ci(.$total_crashes)) %>%
  ungroup %>%
  mutate(branch=factor(branch, c("default", "enabled"), c("Gecko", "WebRender"))) %>%
  ggplot(aes(branch, y/usage_hours*1000, ymin=ymin/usage_hours*1000, ymax=ymax/usage_hours*1000)) +
    facet_wrap(~process, nrow=1) +
    geom_col(width=0.3) +
    geom_errorbar(width=0.05) +
    labs(title="By process: crashes per 1000 usage hours", y="Crashes / 1000 hr", x="Branch") +
    geom_text(aes(label=format(y/usage_hours*1000, digits=3)), nudge_y=0.15) +
    ylim(0, 3)
```

### OOM crash reports

```{r oom_crashes}
crashes %>%
  filter(crash == "oom_crashes") %>%
  mutate(branch=factor(branch, c("default", "enabled"), c("Gecko", "WebRender"))) %>%
  ggplot(aes(branch, y/usage_hours*1000, ymin=ymin/usage_hours*1000, ymax=ymax/usage_hours*1000)) +
    geom_col(width=0.3) +
    geom_errorbar(width=0.05) +
    labs(title="OOM crashes: crashes per 1000 usage hours", y="Crashes / 1000 hr", x="Branch") +
    geom_text(aes(label=format(y/usage_hours*1000, digits=3)), nudge_y=0.15) +
    ylim(0, 3)
```

### WebGL canvas construction

Failure to create a WebGL canvas was rare in either branch.

```{r webgl_success}
per_user %>%
  filter(metric == "webgl_success") %>%
  filter(!is.na(mean)) %>%
  mutate(branch=factor(branch, c("default", "enabled"), c("Gecko", "WebRender"))) %>%
  group_by(branch) %>%
  summarize(average_success_fraction=sum(mean)/n()) %>%
  knitr::kable()
```

### Device resets

```{r reset_crashes}
crashes %>%
  filter(crash == "device_reset_reason_total") %>%
  mutate(branch=factor(branch, c("default", "enabled"), c("Gecko", "WebRender"))) %>%
  ggplot(aes(branch, y/usage_hours*1000, ymin=ymin/usage_hours*1000, ymax=ymax/usage_hours*1000)) +
    geom_col(width=0.3) +
    geom_errorbar(width=0.05) +
    labs(title="Device resets: resets per 1000 usage hours", y="Resets / 1000 hr", x="Branch") +
    geom_text(aes(label=format(y/usage_hours*1000, digits=3)), nudge_y=0.3)
```

## Engagement

Retention and engagement metrics were observed for all enrolled users from the moment of enrollment;
filtering was not performed to ensure that the compositor matched the enrolled branch,
and enrollment sessions were not discarded.

### URI count

Total URIs visited in each branch were indistinguishable.

```{r total_uri_cdf}
engagement %>%
  transform_branch %>%
  ggplot(aes(total_uris+1, color=branch)) +
    stat_ecdf() +
    coord_cartesian(xlim=c(1, 1e5)) +
    scale_x_log10() +
    scale_color_discrete("Branch") +
    labs(title="Distribution of the total count of URIs visited by users in each branch")
```

Computing bootstrapped 95% confidence intervals for the difference between the distributions along the curve,
the intervals all contain zero:

```{r total_uri_quantiles}
quantile_delta = function(data, i, var, q) {
  sample = data[i,]
  wr = quantile(sample[sample$branch == "enabled",][[var]], q)
  gecko = quantile(sample[sample$branch == "default",][[var]], q)
  ((wr - gecko) / gecko) * 100
}

engagement_boot = function(x) {
  boot(x, quantile_delta, N_BOOT, strata=factor(x$branch), parallel="multicore", ncpus=4, var="value", q=c(0.10, 0.25, 0.5, 0.75, 0.95)) %>%
    tidy(conf.int=TRUE, conf.method="basic")
}

engagement_quantiles = engagement %>%
  gather("metric", "value", -branch) %>%
  group_by(metric) %>%
  do(engagement_boot(.)) %>%
  ungroup

engagement_quantiles %>%
  filter(metric == "total_uris") %>%
  ggplot(aes(term, statistic, ymin=conf.low, ymax=conf.high)) +
    geom_point(size=3) +
    geom_hline(yintercept=0, alpha=0.6) +
    geom_errorbar(width=0.2) +
    labs(x="Percentile", y="(WebRender - Gecko)/Gecko (%)", title="total_uri_count: percent difference between WR and Gecko")
```

### Active time

The distribution of per-user active time was similar between branches:

```{r active_time_cdf}
engagement %>%
  transform_branch %>%
  ggplot(aes(active_time_hr+1, color=branch)) +
    stat_ecdf() +
    scale_x_log10() +
    scale_color_discrete("Branch") +
    coord_cartesian(xlim=c(1, 300)) +
    labs(title="Distribution of the total per-user active time in each branch")
```

Active time may have decreased slightly for WebRender branch users among less avid users,
which could reflect either a more efficient browsing experience or less browsing.

```{r active_time_quantiles}
engagement_quantiles %>%
  filter(metric == "active_time_hr") %>%
  ggplot(aes(term, statistic, ymin=conf.low, ymax=conf.high)) +
    geom_point(size=3) +
    geom_hline(yintercept=0, alpha=0.6) +
    geom_errorbar(width=0.2) +
    labs(x="Percentile", y="(WebRender - Gecko)/Gecko (%)", title="active_ticks: percent difference between WR and Gecko")
```

### Total time

Distribution of total browser-open time was similar between branches.

```{r session_time_cdf}
engagement %>%
  transform_branch %>%
  ggplot(aes(session_length_hr+1, color=branch)) +
    stat_ecdf() +
    scale_x_log10() +
    scale_color_discrete("Branch") +
    coord_cartesian(xlim=c(1, 1000)) +
    labs(title="Distribution of the total per-user browser-open time in each branch") +
    geom_vline(xintercept=504) +
    annotate(geom="text", x=520, y=0.8, label="Study\nduration", hjust=0)
```

Similar to active time, less-avid users may have used the browser slightly less
in the WebRender branch.

```{r session_time_quantiles}
engagement_quantiles %>%
  filter(metric == "session_length_hr") %>%
  ggplot(aes(term, statistic, ymin=conf.low, ymax=conf.high)) +
    geom_point(size=3) +
    geom_hline(yintercept=0, alpha=0.6) +
    geom_errorbar(width=0.2) +
    labs(x="Percentile", y="(WebRender - Gecko)/Gecko (%)", title="Total time: percent difference between WR and Gecko")
```

## Retention

Retention was similar between the study branches.

```{r retention}

retention_conf = retention %>%
  transform_branch %>%
  group_by_all() %>%
  do(Hmisc::binconf(.$n, .$week_0, return.df=TRUE)) %>%
  ungroup

ggplot(retention_conf, aes(weeks_since_enrollment, PointEst, ymin=Lower, ymax=Upper, color=branch)) +
  geom_line(alpha=0.3) +
  geom_point(position=position_dodge(width=0.2), size=2) +
  geom_errorbar(position=position_dodge(width=0.2), width=0.15) +
  scale_x_continuous(breaks=c(0, 1, 2)) +
  labs(x="Weeks since enrollment", y="% of users retained", title="Retention")
```

## Enrollment

Daily enrollment and unenrollment were symmetric between branches.

```{r cumulative_enrollment}
enroll_daily %>%
  transform_branch %>%
  mutate(enrollment_date=as.Date(enrollment_date)) %>%
  arrange(branch, enrollment_date) %>%
  group_by(branch) %>%
  mutate(cumulative=cumsum(n)) %>%
  ungroup %>%
  ggplot(aes(enrollment_date, cumulative, color=branch)) +
    geom_line() +
    expand_limits(y=0) +
    labs(x="Enrollment date", y="Users enrolled", title="Cumulative enrollment, by branch")
```

Unenrollments were minimal and distributed equally between branches.

```{r cumulative_unenrollment}
unenroll_daily %>%
  transform_branch %>%
  mutate(first_unenrollment_date=as.Date(first_unenrollment_date)) %>%
  arrange(branch, first_unenrollment_date) %>%
  group_by(branch) %>%
  mutate(cumulative=cumsum(n)) %>%
  ungroup %>%
  ggplot(aes(first_unenrollment_date, cumulative, color=branch)) +
    geom_line() +
    labs(x="Date", y="Number of users", title="Cumulative premature unenrollment, by branch")
```

# Conclusions

* The WebRender experiment met all but one of the performance goals.
  Although the median per-user mean `CONTENT_FULL_PAINT_TIME` increased,
  the number of measurements greater than 16 ms (=1/60 Hz) actually decreased.
  Because most users have a 60 Hz refresh rate, this may not be a generally user-visible regression.
* The WebRender experiment had generally salutary effects on stability,
  except for an increase in GPU process crashes.
  Main process and content process crashes, which are more visible to the user, decreased.
* The WebRender experiment did not have clear impacts on user engagement or retention.

# Methods

The [`webrender-performance-66` experiment][experimenter] enrolled users
in Firefox 66 who met the
`normandy.telemetry.main.environment.system.gfx.features.wrQualified.status == 'available'` criterion.
At the time of the study, this enrolled users running Windows 10
on systems without a battery
and having one of a list of whitelisted graphics cards.

ETL was computed by two notebooks:

* [Engagement and retention](https://dbc-caf9527b-e073.cloud.databricks.com/#notebook/103517/command/104697)
* [Performance](https://dbc-caf9527b-e073.cloud.databricks.com/#notebook/94118/command/94218)
