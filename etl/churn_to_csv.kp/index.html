<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<title> Knowledge </title>
<!-- js includes at the top as post embedded js colliding -->
<script src="/static/legacy/knowledge-repo/modules/jquery/jquery.min.js"></script>
<script src="/static/legacy/knowledge-repo/modules/tether/js/tether.min.js"></script>
<script src="/static/legacy/knowledge-repo/modules/bootstrap/js/bootstrap.min.js"></script>
<script src="/static/legacy/knowledge-repo/modules/bootstrap-slider/js/bootstrap-slider.min.js"></script>
<script src="/static/legacy/knowledge-repo/modules/typeahead.js/typeahead.bundle.min.js"></script>
<script src="/static/legacy/knowledge-repo/modules/handlebars/js/handlebars.js"></script>
<script src="/static/legacy/knowledge-repo/js/helpers.js"></script>
<script src="/static/legacy/knowledge-repo/modules/select2/js/select2.min.js"></script>
<script src="/static/legacy/knowledge-repo/modules/hightlight.pack.js/highlight.pack.js"></script>
<script src="/static/legacy/knowledge-repo/modules/marked.js/marked.js"></script>
<!-- require js is used for plotly, but has a bunch of collisions with other js packages
             make sure to have it be last js package imported -->
<script src="/static/legacy/knowledge-repo/modules/require.js/require.min.js"></script>
<!--[if lt IE 9]>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.2/html5shiv.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/2.1.0/es5-shim.min.js"></script>
        <![endif]-->
<link href="/static/legacy/knowledge-repo/modules/bootstrap/css/bootstrap.min.css" rel="stylesheet"/>
<link href="/static/legacy/knowledge-repo/modules/bootstrap-slider/css/bootstrap-slider.min.css" rel="stylesheet"/>
<link href="/static/legacy/knowledge-repo/css/custom.css" rel="stylesheet" type="text/css"/>
<link href="/static/legacy/knowledge-repo/modules/select2/css/select2.min.css" rel="stylesheet" type="text/css"/>
<link href="https://fonts.googleapis.com/css?family=Lato:400,900|Playfair+Display|Source+Serif+Pro:400,700" rel="stylesheet" type="text/css"/>
<link href="/static/legacy/knowledge-repo/images/favicon.png" rel="shortcut icon"/>
<link href="/static/legacy/knowledge-repo/css/codehilite-friendly.css" rel="stylesheet"/>
<style>
            .spinner {
                position: fixed;
                top: 50%;
                left: 50%;
                margin-left: -50px; /* half width of the spinner gif */
                margin-top: -50px; /* half height of the spinner gif */
                text-align:center;
                z-index:1234;
                overflow: auto;
                width: 100px; /* width of the spinner gif */
                height: 102px; /*hight of the spinner gif +2px to fix IE8 issue */
            }

            .table {
              font-size: 14px;
            }

            .modal-content {
              max-width: 1024px;
            }

             

          </style>
</head>
<body>

<div class="container page-container">
<br/>
<div class="container-fluid">
<div class="row">
<div class="col-md-6">

</div>
<div class="col-md-2">
</div>

</div>
<div class="row col-md-12">
</div>
</div>
<div class="container-fluid">
<div class="row">
<div class="col-md-12">
<div id="renderedMarkdown">
<div class="metadata">
<h1>Churn to CSV</h1>
<span class="authors"><a href="/feed?authors=amiyaguchi">amiyaguchi</a></span>
<span class="date_created">March 07, 2016</span>
<span class="date_updated">(Last Updated: April 18, 2017)</span>
<span class="tldr"><p>Convert telemetry-parquet/churn to csv</p></span>

</div>
<h1 id="churn-to-csv">Churn to CSV</h1>
<p><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1345217">Bug 1345217</a></p>
<p>This script turns the parquet dataset generated by <a href="https://github.com/mozilla/mozilla-reports/blob/master/etl/churn.kp/knowledge.md">churn notebook</a> into csv files.</p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">boto3</span>
<span class="kn">import</span> <span class="nn">botocore</span>
<span class="kn">import</span> <span class="nn">gzip</span>

<span class="kn">from</span> <span class="nn">boto3.s3.transfer</span> <span class="kn">import</span> <span class="n">S3Transfer</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span> <span class="n">timedelta</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>


<span class="k">def</span> <span class="nf">csv</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
    <span class="k">return</span> <span class="s2">","</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">unicode</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">f</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">fmt</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">date_format</span><span class="o">=</span><span class="s2">"%Y%m</span><span class="si">%d</span><span class="s2">"</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">datetime</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">date_format</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">collect_and_upload_csv</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">upload_config</span><span class="p">):</span>
    <span class="sd">""" Collect the dataframe into a csv file and upload to target locations. """</span>
    <span class="n">client</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">client</span><span class="p">(</span><span class="s1">'s3'</span><span class="p">,</span> <span class="s1">'us-west-2'</span><span class="p">)</span>
    <span class="n">transfer</span> <span class="o">=</span> <span class="n">S3Transfer</span><span class="p">(</span><span class="n">client</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s2">"{}: Writing output to {}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">utcnow</span><span class="p">(),</span> <span class="n">filename</span><span class="p">))</span>

    <span class="c1"># Write the file out as gzipped csv</span>
    <span class="k">with</span> <span class="n">gzip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">fout</span><span class="p">:</span>
        <span class="n">fout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">","</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span> <span class="o">+</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">"{}: Wrote header to {}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">utcnow</span><span class="p">(),</span> <span class="n">filename</span><span class="p">))</span>
        <span class="n">records</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">rdd</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">records</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">fout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">csv</span><span class="p">(</span><span class="n">r</span><span class="p">))</span>
                <span class="n">fout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">UnicodeEncodeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="s2">"{}: Error writing line: {} // {}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">utcnow</span><span class="p">(),</span> <span class="n">e</span><span class="p">,</span> <span class="n">r</span><span class="p">))</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">"{}: finished writing lines"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">utcnow</span><span class="p">()))</span>

    <span class="c1"># upload files to s3</span>
    <span class="k">try</span><span class="p">:</span> 
        <span class="k">for</span> <span class="n">config</span> <span class="ow">in</span> <span class="n">upload_config</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">"{}: Uploading to {} at s3://{}/{}/{}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">datetime</span><span class="o">.</span><span class="n">utcnow</span><span class="p">(),</span> <span class="n">config</span><span class="p">[</span><span class="s2">"name"</span><span class="p">],</span> <span class="n">config</span><span class="p">[</span><span class="s2">"bucket"</span><span class="p">],</span> 
                    <span class="n">config</span><span class="p">[</span><span class="s2">"prefix"</span><span class="p">],</span> <span class="n">filename</span><span class="p">))</span>

            <span class="n">s3_path</span> <span class="o">=</span> <span class="s2">"{}/{}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"prefix"</span><span class="p">],</span> <span class="n">filename</span><span class="p">)</span>
            <span class="n">transfer</span><span class="o">.</span><span class="n">upload_file</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">config</span><span class="p">[</span><span class="s2">"bucket"</span><span class="p">],</span> <span class="n">s3_path</span><span class="p">,</span>
                                 <span class="n">extra_args</span><span class="o">=</span><span class="p">{</span><span class="s1">'ACL'</span><span class="p">:</span> <span class="s1">'bucket-owner-full-control'</span><span class="p">})</span>
    <span class="k">except</span> <span class="n">botocore</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">ClientError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">"File for {} already exists, skipping upload: {}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">e</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">marginalize_dataframe</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">attributes</span><span class="p">,</span> <span class="n">aggregates</span><span class="p">):</span>
    <span class="sd">""" Reduce the granularity of the dataset to the original set of attributes.</span>
<span class="sd">    The original set of attributes can be found on commit 2de3ef1 of mozilla-reports. """</span>

    <span class="k">return</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">attributes</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">F</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">aggregates</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">convert_week</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">week_start</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">""" Convert a given retention period from parquet to csv. """</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"source"</span><span class="p">])</span>

    <span class="c1"># find the latest start date based on the dataset if not provided</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">week_start</span><span class="p">:</span>
        <span class="n">start_dates</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">"week_start"</span><span class="p">)</span><span class="o">.</span><span class="n">distinct</span><span class="p">()</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
        <span class="n">week_start</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">start_dates</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">week_start</span>

    <span class="c1"># find the week end for the filename</span>
    <span class="n">week_end</span> <span class="o">=</span> <span class="n">fmt</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">strptime</span><span class="p">(</span><span class="n">week_start</span><span class="p">,</span> <span class="s2">"%Y%m</span><span class="si">%d</span><span class="s2">"</span><span class="p">)</span> <span class="o">+</span> <span class="n">timedelta</span><span class="p">(</span><span class="mi">6</span><span class="p">))</span>

    <span class="k">print</span><span class="p">(</span><span class="s2">"Running for the week of {} to {}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">week_start</span><span class="p">,</span> <span class="n">week_end</span><span class="p">))</span>

    <span class="c1"># find the target subset of data</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">week_start</span> <span class="o">==</span> <span class="n">week_start</span><span class="p">)</span>

    <span class="c1"># marginalize the dataframe to the original attributes and upload to s3</span>
    <span class="n">initial_attributes</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'channel'</span><span class="p">,</span> <span class="s1">'geo'</span><span class="p">,</span> <span class="s1">'is_funnelcake'</span><span class="p">,</span>
                          <span class="s1">'acquisition_period'</span><span class="p">,</span> <span class="s1">'start_version'</span><span class="p">,</span> <span class="s1">'sync_usage'</span><span class="p">,</span>
                          <span class="s1">'current_version'</span><span class="p">,</span> <span class="s1">'current_week'</span><span class="p">,</span> <span class="s1">'is_active'</span><span class="p">]</span>
    <span class="n">initial_aggregates</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'n_profiles'</span><span class="p">,</span> <span class="s1">'usage_hours'</span><span class="p">,</span> <span class="s1">'sum_squared_usage_hours'</span><span class="p">]</span>

    <span class="n">upload_df</span> <span class="o">=</span> <span class="n">marginalize_dataframe</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">initial_attributes</span><span class="p">,</span> <span class="n">initial_aggregates</span><span class="p">)</span>
    <span class="n">filename</span> <span class="o">=</span> <span class="s2">"churn-{}-{}.by_activity.csv.gz"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">week_start</span><span class="p">,</span> <span class="n">week_end</span><span class="p">)</span>
    <span class="n">collect_and_upload_csv</span><span class="p">(</span><span class="n">upload_df</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">config</span><span class="p">[</span><span class="s2">"uploads"</span><span class="p">])</span>

    <span class="c1"># Bug 1355988</span>
    <span class="c1"># The size of the data explodes significantly with extra dimensions and is too</span>
    <span class="c1"># large to fit into the driver memory. We can write directly to s3 from a</span>
    <span class="c1"># dataframe.</span>
    <span class="n">bucket</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'search_cohort'</span><span class="p">][</span><span class="s1">'bucket'</span><span class="p">]</span>
    <span class="n">prefix</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'search_cohort'</span><span class="p">][</span><span class="s1">'prefix'</span><span class="p">]</span>
    <span class="n">location</span> <span class="o">=</span> <span class="s2">"s3://{}/{}/week_start={}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">bucket</span><span class="p">,</span> <span class="n">prefix</span><span class="p">,</span> <span class="n">week_start</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s2">"Saving additional search cohort churn data to {}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">location</span><span class="p">))</span>

    <span class="n">search_attributes</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">'source'</span><span class="p">,</span> <span class="s1">'medium'</span><span class="p">,</span> <span class="s1">'campaign'</span><span class="p">,</span> <span class="s1">'content'</span><span class="p">,</span>
        <span class="s1">'distribution_id'</span><span class="p">,</span> <span class="s1">'default_search_engine'</span><span class="p">,</span> <span class="s1">'locale'</span>
    <span class="p">]</span>
    <span class="n">attributes</span> <span class="o">=</span> <span class="n">initial_attributes</span> <span class="o">+</span> <span class="n">search_attributes</span>
    <span class="n">upload_df</span> <span class="o">=</span> <span class="n">marginalize_dataframe</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">attributes</span><span class="p">,</span> <span class="n">initial_aggregates</span><span class="p">)</span>
    <span class="n">upload_df</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="n">location</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'overwrite'</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">'gzip'</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s2">"Sucessfully finished churn_to_csv"</span><span class="p">)</span>
</pre></div>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">assert_valid_config</span><span class="p">(</span><span class="n">config</span><span class="p">):</span>
    <span class="sd">""" Assert that the configuration looks correct. """</span>
    <span class="c1"># This could be replaced with python schema's</span>
    <span class="k">assert</span> <span class="nb">set</span><span class="p">([</span><span class="s2">"source"</span><span class="p">,</span> <span class="s2">"uploads"</span><span class="p">,</span> <span class="s2">"search_cohort"</span><span class="p">])</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="k">assert</span> <span class="nb">set</span><span class="p">([</span><span class="s2">"bucket"</span><span class="p">,</span> <span class="s2">"prefix"</span><span class="p">])</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s1">'search_cohort'</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">config</span><span class="p">[</span><span class="s2">"uploads"</span><span class="p">]:</span>
        <span class="k">assert</span> <span class="nb">set</span><span class="p">([</span><span class="s2">"name"</span><span class="p">,</span> <span class="s2">"bucket"</span><span class="p">,</span> <span class="s2">"prefix"</span><span class="p">])</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="n">entry</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</pre></div>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">moztelemetry.standards</span> <span class="kn">import</span> <span class="n">snap_to_beginning_of_week</span>
<span class="kn">from</span> <span class="nn">os</span> <span class="kn">import</span> <span class="n">environ</span>

<span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"source"</span><span class="p">:</span> <span class="s2">"s3://telemetry-parquet/churn/v2"</span><span class="p">,</span>
    <span class="s2">"uploads"</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">"name"</span><span class="p">:</span>   <span class="s2">"Pipeline-Analysis"</span><span class="p">,</span>
            <span class="s2">"bucket"</span><span class="p">:</span> <span class="s2">"net-mozaws-prod-us-west-2-pipeline-analysis"</span><span class="p">,</span>
            <span class="s2">"prefix"</span><span class="p">:</span> <span class="s2">"mreid/churn"</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="s2">"name"</span><span class="p">:</span>   <span class="s2">"Dashboard"</span><span class="p">,</span>
            <span class="s2">"bucket"</span><span class="p">:</span> <span class="s2">"net-mozaws-prod-metrics-data"</span><span class="p">,</span>
            <span class="s2">"prefix"</span><span class="p">:</span> <span class="s2">"telemetry-churn"</span>
        <span class="p">}</span>
    <span class="p">],</span>
    <span class="s2">"search_cohort"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">"bucket"</span><span class="p">:</span> <span class="s2">"net-mozaws-prod-us-west-2-pipeline-analysis"</span><span class="p">,</span>
        <span class="s2">"prefix"</span><span class="p">:</span> <span class="s2">"amiyaguchi/churn_csv"</span>
    <span class="p">}</span>
<span class="p">}</span>
<span class="n">assert_valid_config</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

<span class="c1"># Set to True to overwrite the configuration with debugging route</span>
<span class="k">if</span> <span class="bp">False</span><span class="p">:</span>
    <span class="n">config</span><span class="p">[</span><span class="s2">"uploads"</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">"name"</span><span class="p">:</span>   <span class="s2">"Testing"</span><span class="p">,</span>
            <span class="s2">"bucket"</span><span class="p">:</span> <span class="s2">"net-mozaws-prod-us-west-2-pipeline-analysis"</span><span class="p">,</span>
            <span class="s2">"prefix"</span><span class="p">:</span> <span class="s2">"amiyaguchi/churn_csv_testing"</span>
        <span class="p">}</span>
    <span class="p">]</span>
    <span class="n">config</span><span class="p">[</span><span class="s1">'search_cohort'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">"bucket"</span><span class="p">:</span> <span class="s2">"net-mozaws-prod-us-west-2-pipeline-analysis"</span><span class="p">,</span>
        <span class="s2">"prefix"</span><span class="p">:</span> <span class="s2">"amiyaguchi/churn_csv_testing"</span>
    <span class="p">}</span>
    <span class="n">assert_valid_config</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>


<span class="c1"># check for a date, in the case of a backfill</span>
<span class="n">env_date</span> <span class="o">=</span> <span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'date'</span><span class="p">)</span>
<span class="n">week_start</span> <span class="o">=</span> <span class="bp">None</span>
<span class="k">if</span> <span class="n">env_date</span><span class="p">:</span>
    <span class="c1"># Churn waits 10 days for pings to be sent from the client</span>
    <span class="n">week_start_date</span> <span class="o">=</span> <span class="n">snap_to_beginning_of_week</span><span class="p">(</span>
        <span class="n">datetime</span><span class="o">.</span><span class="n">strptime</span><span class="p">(</span><span class="n">env_date</span><span class="p">,</span> <span class="s2">"%Y%m</span><span class="si">%d</span><span class="s2">"</span><span class="p">)</span> <span class="o">-</span> <span class="n">timedelta</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
        <span class="s2">"Sunday"</span><span class="p">)</span>
    <span class="n">week_start</span> <span class="o">=</span> <span class="n">fmt</span><span class="p">(</span><span class="n">week_start_date</span><span class="p">)</span>

<span class="n">convert_week</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">week_start</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div></body></html>
<div>

</div>


<br/>
<div class="row">
<div class="col-md-12">
</div>
</div>




<script type="text/javascript">
            $("#searchbar")[0].setSelectionRange(1000, 1000);

            $('#searchbar').typeahead({
                hint: false,
                highlight: true,
                minLength: 1
              },
              {
                name: 'knowledge_posts',
                limit: 10,
                display: function (item) {
                  return item.title + " - " + item.author;
                },
                templates: {
                  empty: Handlebars.compile(
                    '<div class="tt-not-found">' +
                      'Unable to find any posts that match the current query' +
                      '</div>'
                  ),
                  suggestion: function(data) {
                    return '<p style="overflow-wrap:break-word"><strong class="text-rausch">' + data.title + '</strong> – ' + data.author + '</p>';
                  }
                },
                source: function(q, sync, async) {
                  $.ajax('/ajax/index/typeahead?search=' + q,
                  {
                    success: function(data,status){ async(JSON.parse(data)); }
                  })
                }
              });


            $('#searchbar').bind('typeahead:select', function(obj, datum, name) {
              window.location = '/post/'+encodeURIComponent(datum.path);
            });

            $('#searchbar').keypress(function(event){
              var keycode = (event.keyCode ? event.keyCode : event.which);
              if(keycode == '13'){
                var path = document.location.pathname;
                window.location = '/feed?filters=' + $('#searchbar').val()
              }
            });

            var padding = $('.tt-menu').outerWidth()
            $('.tt-menu').width($('#searchbar').width() + padding + "px")

        </script>
<script src="/static/legacy/knowledge-repo/js/tooltips.js" type="text/javascript"></script>
<script type="text/javascript">
$("document").ready(function(){
  var is_webeditor = false;
  
  var post_id = "25";
  var id = "None";
  var post_path = "etl/churn_to_csv.kp"
  var data_repo_github_root = ""
  tooltipsJx.initializeTooltips(is_webeditor, post_id, id, data_repo_github_root);

  $(".btn-rendered").on("click", function(){
    document.location.href = "/post/" + encodeURI(post_path);
  })

  $(".btn-raw").on("click", function(){
    document.location.href = "/post/" + encodeURI(post_path) + "?render=raw";
  })

  $(".btn-webeditor").on("click", function(){
    document.location.href = "/edit/" + encodeURI(post_path);
  })
});

</script>
<script src="/static/legacy/knowledge-repo/js/helpers.js"></script>
<script src="/static/legacy/knowledge-repo/js/tags.js" type="text/javascript"></script>
<script src="/static/legacy/knowledge-repo/js/icons.js" type="text/javascript"></script>
<script src="/static/legacy/knowledge-repo/js/comments.js" type="text/javascript"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js" type="text/javascript">
</script>
<script>
$(document).on('ready', function(){
  // Make the Rendered Markdown Button active
  $(".btn-rendered").addClass("btn-active");

  // Initialize headers
  helpersJx.linkifyHeaders();

  // Initialize comments
  var post_path = 'etl/churn_to_csv.kp';

  $("#post_comment_btn").on('click', function(){
      comment_author = 'knowledge_default';
      post_author = 'amiyaguchi';
      post_title = 'Churn to CSV';
      commentsJx.postComment(comment_author, post_author, post_title, post_path);
      location.reload();
  });

  all_comment_delete_buttons = $("[id^=delete_comment]")
  $.each(all_comment_delete_buttons, function(i,v){
      $(v).on("click", function(){
          var id = v.id;
          var comment_id = id.split("__")[1];
          if(comment_id) {
            commentsJx.deleteComment(post_path, comment_id)
            location.reload();
          }
      });
  });
  $(document.body).on('click',"button[id^=tag-subscription]",function () {
    tagsJx.addTagSubscriptionListener($(this)[0]);
  });
})

//Turn all the headers to be links
//h1 = Title, don't want that
var all_headers = [$("h2"), $("h3"), $("h4"), $("h5"), $("h6")]
$.each(all_headers, function(index, value){
  $.each(value, function(i, v){
    var inner_html = v.innerHTML
    inner_html_no_special = inner_html.replace(/[^a-zA-Z\- ]/g, "")
    var inner_link = "#" + inner_html_no_special.toLowerCase().split(" ").join("-")
    v.innerHTML = "<a href='" + inner_link + "' class=link-reset>" + inner_html + "</a>"
  })
})

//turn all the tags into links, similar to what's done on the feed page
var tags = $("#renderedMarkdown .metadata .tags")[0]
var tags_list = ['churn', 'etl', 'csv']
var subscriptions_list = []
$.each(tags_list, function(i,tag){
  ahref = document.createElement("a")
  e_tag = encodeURIComponent(tag)
  f_tag = tag.replace("/", "__")
  tag_name = "#" + tag
  tag_subscription_button_id_name = "tag-subscription-" + i + "__" + f_tag
  ahref.setAttribute("data-container", "body")
  ahref.setAttribute("data-toggle", "popover")
  ahref.setAttribute("data-placement", "bottom")
  ahref.setAttribute("data-html", "true")
  ahref.setAttribute("data-tag-name", f_tag)
  if (subscriptions_list.indexOf(tag) >= 0) {
    ahref.setAttribute("class", "label label-subscribed pop")
    ahref.setAttribute("data-content", "<div class='content'>" +
                  " <button class='btn btn-small btn-primary btn-unsubscribe'" +
                        " title='' " +
                          " id='" + tag_subscription_button_id_name + "'> " +
                    " <i class='glyphicon glyphicon-remove-sign glyphicon-white'></i>Unsubscribe " +
                  " </button> " +
                  " </div>")
  } else {
    ahref.setAttribute("class", "label label-unsubscribed pop")
    ahref.setAttribute("data-content", "<div class='content'>" +
                  " <button class='btn btn-small btn-default btn-subscribe'" +
                        " title='' " +
                          " id='" + tag_subscription_button_id_name + "'> " +
                    " <i class='glyphicon glyphicon-ok-sign glyphicon-filled'></i>Subscribe " +
                  " </button> " +
                  " </div>")
  }
  ahref.setAttribute("href", "/tag_pages?tag=" + e_tag)
  ahref.setAttribute("style", "font-weight:normal")
  if (i == 0){
    ahref.innerHTML = " "
    colon = document.createElement("text")
    colon.innerHTML = "<b>Tags</b>: "
    tags.appendChild(colon)
  }
  ahref.innerHTML = ahref.innerHTML + tag_name
  tags.appendChild(ahref)
  if (i != tags_list.length - 1){
    comma = document.createElement("text")
    comma.innerText = ", "
    tags.appendChild(comma)
  }
})
tags.nextSibling.remove()

tags.innerHTML += "<i class='glyphicon glyphicon-edit icon-gray' style='font-size:12pt; padding-left:4px' id='tooltip-edit_tags'></i>"

$(".pop").popover({ trigger: "manual" , html: true, animation:false, delay: 100})
  .on("mouseenter", function () {
      var _this = this;
      $(this).popover("show");
      $(".popover").on("mouseleave", function () {
          $(_this).popover('hide');
      });
  }).on("mouseleave", function () {
      var _this = this;
      setTimeout(function () {
          if (!$(".popover:hover").length) {
              $(_this).popover("hide");
          }
      }, 300);
});

$('#tooltip-edit_tags').click(function(){
  $('#tooltip-edit_tags')[0].setAttribute("style", "display:none")
  previousSibling = $("#tooltip-edit_tags")[0].previousSibling
  tags_string = tags_list.join(", ")
  form = document.createElement("form")
  input = document.createElement("input")
  tags_text = document.createElement("text")
  icon_class = document.createElement("i")
  icon_class.setAttribute("class", "glyphicon glyphicon-upload icon-gray")
  icon_class.setAttribute("style", "font-size:23px; padding-left:4px")
  icon_class.setAttribute("id", "tooltip-save_tags")
  tags_text.innerText = "Tags: "
  input.setAttribute('type', 'text')
  input.setAttribute('name', 'tags_list')
  input.setAttribute('value', tags_string)
  input.setAttribute('style', 'width:75%; display: inline-block')
  input.setAttribute('id' , 'change_tags')
  form.appendChild(tags_text)
  tags.textContent = " "
  form.appendChild(input)
  form.appendChild(icon_class)
  tags.appendChild(form)


  $("#tooltip-save_tags").click(function(){
    tags_string = $("#change_tags")[0].value
    tags_list = tags_string.split(",")

    var re = /^[a-z0-9\-\_\:\/]+$/i
    var good = true
    for (var i = 0; i < tags_list.length; i++){
      tag = tags_list[i]
      if (tag.length == 0){
        alert("There is a tag with length 0 - possible a trailing comma?")
        good = false
        break
      } else {
        tag_name = tag.trim()
        if (!(re.test(tag_name))){
           alert("The tag contains special characters. Make sure there are only alphanumeric characters in your tag")
           good = false
           break
        }
      }
    }
    if (good) {
    var postContent = {}
      postContent['tags'] = tags_string
      $.ajax({
        type: "POST",
        dataType: "json",
        data: JSON.stringify(postContent),
        contentType: "application/json",
        url: '/tag_list?post_path=etl/churn_to_csv.kp',
        async: false
      });
      location.reload()
    }
  })

  tags.nextSibling.remove()

  // Allow user to edit tags
  var edit_icon = iconsJx.createEditTagsIcon();
  $(tags).after(edit_icon);

  $("#tooltip-edit_tags").on("click", function(){
      var edit_tooltip = $("#tooltip-edit_tags");
      edit_tooltip.attr("style", "display:none");

      var tags_string = tags_list.join(", ");
      var form = $("<form>");
      var input = $("<input>");

      var tags_text = $("<text>");
      tags_text.html("Tags: ");


      var icon = iconsJx.createSaveTagsIcon();

      input.attr("type", "text");
      input.attr("name", "tags_list");
      input.attr("style", "width:75%; display: inline-block");
      input.attr("id", "change_tags");

      form.append(tags_text);
      tags.textContent = " ";
      tags_text.innerHTML = "Tags: ";
      form.append(input);
      form.append(icon);
      tags.appendChild(form[0]);
      $("#change_tags")[0].value = tags_string;


      $("#change_tags").keypress(function(e){
          if (e.which == 13){
              var tags_string = $("#change_tags")[0].value;
              var post_path = "etl/churn_to_csv.kp";
              tagsJx.changeAndSaveTags(post_path, tags_string);
              return false;
          };
      });


      $("#tooltip-save_tags").click(function(){
          var tags_string = $("#change_tags")[0].value;
          var post_path = "etl/churn_to_csv.kp";
          tagsJx.changeAndSaveTags(post_path, tags_string);
      });

       $("form").submit(function(){
          var tags_string = $("#change_tags")[0].value;
          var post_path = "etl/churn_to_csv.kp";
          tagsJx.changeAndSaveTags(post_path, tags_string);
          return false
      })
  });

});

</script>


