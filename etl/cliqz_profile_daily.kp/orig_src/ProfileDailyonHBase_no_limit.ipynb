{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Cliqz Profile Daily\n",
    "authors:\n",
    "- Ryan Harter (:harter) \n",
    "tags:\n",
    "- Spark\n",
    "- ATMO\n",
    "- ETL\n",
    "created_at: 2017-03-08\n",
    "updated_at: 2017-03-08\n",
    "tldr: Populates cliqz_profile_daily\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.cancelAllJobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Pilot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlContext.read.parquet(\"s3://telemetry-parquet/harter/cliqz_testpilot/v1/\").createOrReplaceTempView('cliqz_testpilot')\n",
    "sqlContext.read.parquet(\"s3://telemetry-parquet/harter/cliqz_testpilottest/v1/\").createOrReplaceTempView('cliqz_testpilottest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "txp_min_query = \"\"\"\n",
    "SELECT tp.client_id, min(date) as min_date\n",
    "FROM cliqz_testpilot tp\n",
    "JOIN cliqz_testpilottest tpt\n",
    "ON tpt.client_id = tp.client_id\n",
    "GROUP BY 1\n",
    "\"\"\"\n",
    "\n",
    "txp_min = sqlContext.sql(txp_min_query)\n",
    "\n",
    "txp_query = \"\"\"\n",
    "SELECT \n",
    "    tp.client_id,\n",
    "    tpt.cliqz_client_id,\n",
    "    tp.submission as submission_date,\n",
    "    tp.cliqz_version,\n",
    "    tp.has_addon,\n",
    "    tp.cliqz_version,\n",
    "    tpt.event,\n",
    "    tp.event as tp_event,\n",
    "    tpt.content_search_engine\n",
    "FROM cliqz_testpilot tp\n",
    "JOIN cliqz_testpilottest tpt\n",
    "ON tpt.client_id = tp.client_id\n",
    "AND tpt.submission == tp.submission\n",
    "\"\"\"\n",
    "txp = sqlContext.sql(txp_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Main Summary data with HBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client_ids = txp_min.rdd.map(lambda x: str(x.client_id)).distinct().collect()\n",
    "\n",
    "import uuid\n",
    "def filter_client_ids(client_id):\n",
    "    try:\n",
    "        uuid.UUID(client_id)\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "clean_clients = filter(filter_client_ids, client_ids)\n",
    "print len(clean_clients)\n",
    "print len(set(clean_clients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "def filter_ms_payload(row):\n",
    "    fields = [\n",
    "        'submission_date',\n",
    "        'normalized_channel',\n",
    "        'os',\n",
    "        'is_default_browser',\n",
    "        'subsession_length',\n",
    "        'default_search_engine',\n",
    "        'search_counts',\n",
    "    ]\n",
    "    \n",
    "    addons = map(lambda x: x['addon_id'],\n",
    "                 row.get('active_addons', []))\n",
    "\n",
    "    return dict(zip(fields, [row.get(ff) for ff in fields]) +\n",
    "                [(\"has_addon\", \"testpilot@cliqz.com\" in addons)])\n",
    "\n",
    "from moztelemetry.hbase import HBaseMainSummaryView\n",
    "view = HBaseMainSummaryView()\n",
    "def read_ms_data(clients):\n",
    "    # This function has difficulty handling more than ~500 clients\n",
    "    # see https://gist.github.com/harterrt/cf0f3812d28f6d4d5cafacfba3308f19\n",
    "    return view.get_range(sc, clients,\n",
    "                       range_start=date(2017,1,1),\n",
    "                       range_end=date.today(), limit=180)\\\n",
    "        .map(lambda (k, v): (k, map(filter_ms_payload, v)))\n",
    "\n",
    "def paginate(seq, slice_len):\n",
    "    # Split a list into a list of lists with length slice_len\n",
    "    for ii in xrange(0, len(seq), slice_len):\n",
    "        yield seq[ii:ii+slice_len]\n",
    "\n",
    "def get_all_ms_data(client_ids):\n",
    "    # Paginate client_ids and pull data\n",
    "    groups = paginate(client_ids, 250)\n",
    "    sharded_data = map(lambda cc: read_ms_data(cc).collect(), groups)\n",
    "    \n",
    "    return sc.parallelize(sharded_data).flatMap(lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ms_list = get_all_ms_data(clean_clients)\n",
    "ms_list.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter to two week window of main summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "def filter_and_flatten(row):\n",
    "    \"\"\"Filter ms_array to rows from no earlier than 2 weeks before expt start\n",
    "    \n",
    "    row: (client_id, (txp_min(client_id, min_date),\n",
    "                      [ms_row_dicts]))\n",
    "    \n",
    "    returns: filtered dicts from main_summary (including client_id)\n",
    "    \"\"\"\n",
    "    \n",
    "    min_date = datetime.strptime(row[1][0].min_date, \"%Y%m%d\")\n",
    "    def is_ms_row_recent(ms_row):\n",
    "        try:\n",
    "            submission_date = datetime.strptime(ms_row['submission_date'], \"%Y%m%d\")\n",
    "            return (min_date - submission_date) <= timedelta(14)\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    filtered = filter(is_ms_row_recent, row[1][1])\n",
    "    \n",
    "    # Add the client_id to the filtered rows:\n",
    "    return map(lambda ms_dict: dict(ms_dict.items() + [('client_id', row[0])]),\n",
    "               filtered)\n",
    "\n",
    "filtered_ms = txp_min.rdd.map(lambda x: (x.client_id, x))\\\n",
    "    .join(ms_list).flatMap(filter_and_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_ms.map(lambda x: x['client_id']).distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate\n",
    "\n",
    "This aggregation is pretty messy. \n",
    "We effectively take an arbitrary value for anything not included in the Counter object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter, namedtuple\n",
    "\n",
    "AggRow = namedtuple(\"AggRow\", ['raw_row', 'agg_field'])\n",
    "\n",
    "def agg_func(x, y):\n",
    "    print x\n",
    "    return x[0], x[1] + y[1]\n",
    "\n",
    "def prep_ms_agg(row):\n",
    "    def parse_search_counts(search_counts):\n",
    "        if search_counts is not None:\n",
    "            return Counter({(xx['engine'] + \"-\" + xx['source']): xx['count'] for xx in search_counts})\n",
    "        else:\n",
    "            return Counter()\n",
    "\n",
    "    return ((row['client_id'], row['submission_date']),\n",
    "        AggRow(\n",
    "            raw_row = row,\n",
    "            agg_field = Counter({\n",
    "                \"is_default_browser_counter\": Counter([row['is_default_browser']]),\n",
    "                \"session_hours\": float(row['subsession_length'] if row['subsession_length'] else 0)/3600,\n",
    "                \"search_counts\": parse_search_counts(row['search_counts']),\n",
    "                \"has_addon\": row['has_addon']\n",
    "            })\n",
    "        )\n",
    "    )\n",
    "\n",
    "def prep_txp_agg(row):\n",
    "    return ((row.client_id, row.submission_date),\n",
    "        AggRow(\n",
    "            raw_row = row,\n",
    "            agg_field = Counter({\n",
    "                \"cliqz_enabled\": int(row.tp_event == \"enabled\"),\n",
    "                \"cliqz_enabled\": int(row.tp_event == \"disabled\"),\n",
    "                \"test_enabled\": int(row.event == \"cliqzEnabled\"),\n",
    "                \"test_disabled\": int(row.event == \"cliqzDisabled\"),\n",
    "                \"test_installed\": int(row.event == \"cliqzInstalled\"),\n",
    "                \"test_uninstalled\": int(row.event == \"cliqzUninstalled\")\n",
    "            })\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agg_ms = filtered_ms.map(prep_ms_agg).reduceByKey(agg_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#agg_ms.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agg_txp = txp.rdd.map(prep_txp_agg).reduceByKey(agg_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#agg_txp.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join aggregated tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined = agg_ms.fullOuterJoin(agg_txp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "profile_daily = Row('client_id', 'cliqz_client_id', 'date', 'has_cliqz',\n",
    "                    'cliqz_version', 'channel', 'os', 'is_default_browser',\n",
    "                    'session_hours', 'search_default', 'search_counts',\n",
    "                    'cliqz_enabled', 'cliqz_disabled', 'test_enabled',\n",
    "                    'test_disabled', 'test_installed', 'test_uninstalled')\n",
    "\n",
    "def option(value):\n",
    "    return lambda func: func(value) if value is not None else None\n",
    "\n",
    "def format_row(row):\n",
    "    print(row)\n",
    "    key = row[0]\n",
    "    value = row[1]\n",
    "    \n",
    "    # Unfortunately, the named tuple labels aren't preserved in spark, \n",
    "    # unpacking the merged values:\n",
    "    main_summary = option(value[0][0] if value[0] is not None else None)\n",
    "    ms_agg = option(value[0][1] if value[0] is not None else None)\n",
    "    testpilot = option(value[1][0] if value[1] is not None else None)\n",
    "    txp_agg = option(value[1][1] if value[1] is not None else None)\n",
    "\n",
    "    search_counts = ms_agg(lambda x:x['search_counts'])\n",
    "    \n",
    "    return Row(\n",
    "        client_id = key[0],\n",
    "        cliqz_client_id = testpilot(lambda x: x.cliqz_client_id),\n",
    "        date = key[1],\n",
    "        has_cliqz = ms_agg(lambda x: bool(x['has_addon'])),\n",
    "        cliqz_version = testpilot(lambda x: x.cliqz_version),\n",
    "        channel = main_summary(lambda x: x['normalized_channel']),\n",
    "        os = main_summary(lambda x: x['os']),\n",
    "        is_default_browser = ms_agg(lambda x: bool(x['is_default_browser_counter'].most_common()[0][0])),\n",
    "        session_hours = ms_agg(lambda x: x['session_hours']),\n",
    "        search_default = main_summary(lambda x: x['default_search_engine']),\n",
    "        search_counts = dict(search_counts) if search_counts is not None else {},\n",
    "        cliqz_enabled = txp_agg(lambda x: x['cliqz_enabled']),\n",
    "        cliqz_disabled = txp_agg(lambda x: x['cliqz_enabled']),\n",
    "        test_enabled = txp_agg(lambda x: x['test_enabled']),\n",
    "        test_disabled = txp_agg(lambda x: x['test_disabled']),\n",
    "        test_installed = txp_agg(lambda x: x['test_installed']),\n",
    "        test_uninstalled = txp_agg(lambda x: x['test_uninstalled'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final = joined.map(format_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ff = final.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#len(ff)\n",
    "#ff[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sqlContext.createDataFrame(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#txp.filter(\"submission_date = 20170211\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#agg_txp.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#agg_ms.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#agg_ms.map(lambda x: x[1][0]['client_id']).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#agg_txp.count() + agg_ms.count() - final.count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "local_final = sqlContext.createDataFrame(final).repartition(1).write.mode(\"overwrite\")\\\n",
    "    .parquet(\"s3n://telemetry-parquet/harter/cliqz_profile_daily/v1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}