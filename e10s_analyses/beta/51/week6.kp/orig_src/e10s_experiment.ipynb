{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"E10s Testing for Beta 51 week 6\"\n",
    "authors:\n",
    "- rvitillo\n",
    "- dzeber\n",
    "- bmiroglio\n",
    "tags:\n",
    "- e10s\n",
    "- experiment\n",
    "- add-ons\n",
    "created_at: 2017-01-10\n",
    "updated_at: 2017-01-10\n",
    "tldr: Analysis of e10s experiment for profiles with and without add-ons\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# E10s testing for Beta 51 week 6: Main analysis\n",
    "\n",
    "(This covers data from 2016-12-28 to 2017-01-04 on Beta 51)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ujson as json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import plotly.plotly as py\n",
    "import IPython\n",
    "import pyspark.sql.functions as fun\n",
    "from pyspark.sql import Row\n",
    "\n",
    "from __future__ import division\n",
    "from moztelemetry.spark import get_pings, get_one_ping_per_client, get_pings_properties\n",
    "from montecarlino import grouped_permutation_test\n",
    "\n",
    "%pylab inline\n",
    "IPython.core.pylabtools.figsize(16, 7)\n",
    "seaborn.set_style('whitegrid')\n",
    "\n",
    "from operator import add\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.defaultParallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def chi2_distance(xs, ys, eps = 1e-10, normalize = True):\n",
    "    \"\"\" The comparison metric for histograms. \"\"\"\n",
    "    histA = xs.sum(axis=0)\n",
    "    histB = ys.sum(axis=0)\n",
    "    \n",
    "    if normalize:\n",
    "        histA = histA/histA.sum()\n",
    "        histB = histB/histB.sum()\n",
    "    \n",
    "    d = 0.5 * np.sum([((a - b) ** 2) / (a + b + eps)\n",
    "        for (a, b) in zip(histA, histB)])\n",
    "\n",
    "    return d\n",
    "\n",
    "def median_diff(xs, ys):\n",
    "    return np.median(xs) - np.median(ys)\n",
    "\n",
    "def make_group_histogram(group_data):\n",
    "    \"\"\" Combine separate client histograms into a single group histogram, normalizing bin counts\n",
    "        to relative frequencies.       \n",
    "    \"\"\"\n",
    "    ## Check for histograms with 0 counts.\n",
    "    client_totals = group_data.map(lambda x: x.sum())\n",
    "    group_data = group_data[client_totals > 0]\n",
    "    ## Convert frequency counts to relative frequency for each client histogram.\n",
    "    group_data = group_data.map(lambda x: x/x.sum())\n",
    "    ## Merge the group's client histograms by adding up the frequencies over all clients\n",
    "    ## in the group, separately for each bin.\n",
    "    group_data = group_data.sum()\n",
    "    ## Convert the merged bin frequencies to relative percentages.\n",
    "    group_data = 100 * group_data / group_data.sum()\n",
    "    return group_data\n",
    "    \n",
    "\n",
    "def compare_histogram(histogram, e10s_addons, none10s_addons, e10s_std=None, none10s_std=None,\n",
    "                      include_diff=True, include_diff_in_diff=True, did_separate_plot=True):\n",
    "    \"\"\" Compare an e10s histogram to a non-e10s one, and graph the results.\n",
    "        \n",
    "        Plots the two histograms overlaid on the same graph, and prints a p-value\n",
    "        for testing whether they are different. If 'include_diff' is True, also\n",
    "        draw a plot of the frequency differences for each bin.\n",
    "        \n",
    "        If 'include_diff_in_diff' is True and data is supplied, include a plot of\n",
    "        differences between addon cohort differences and non-addon cohort differences.\n",
    "    \"\"\"\n",
    "    eTotal = make_group_histogram(e10s_addons)\n",
    "    nTotal = make_group_histogram(none10s_addons)\n",
    "    \n",
    "    if include_diff:\n",
    "        if include_diff_in_diff and did_separate_plot:\n",
    "            fig, (ax, diff_ax, diff_diff_ax) = plt.subplots(3, sharex=True, figsize=(16,10), \n",
    "                                                            gridspec_kw={\"height_ratios\": [2,2,1]})\n",
    "        else:\n",
    "            fig, (ax, diff_ax) = plt.subplots(2, sharex=True)\n",
    "    else:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        \n",
    "    fig.subplots_adjust(hspace=0.3)\n",
    "    ax2 = ax.twinx()\n",
    "    width = 0.4\n",
    "    ylim = max(eTotal.max(), nTotal.max())\n",
    "        \n",
    "    eTotal.plot(kind=\"bar\", alpha=0.5, color=\"green\", label=\"e10s\", ax=ax, width=width,\n",
    "                position=0, ylim=(0, ylim + 1))\n",
    "    nTotal.plot(kind=\"bar\", alpha=0.5, color=\"blue\", label=\"non-e10s\", ax=ax2, width=width,\n",
    "                position=1, grid=False, ylim=ax.get_ylim())\n",
    "    \n",
    "    ## Combine legend info from both Axes.\n",
    "    ax_h, ax_l = ax.get_legend_handles_labels()\n",
    "    ax2_h, ax2_l = ax2.get_legend_handles_labels()\n",
    "    ax.legend(ax_h + ax2_h, ax_l + ax2_l, loc = 0)\n",
    " \n",
    "    plt.title(histogram)\n",
    "    ax.xaxis.grid(False)\n",
    "    ax.set_ylabel(\"Frequency %\")\n",
    "\n",
    "    if include_diff:\n",
    "        ## Add a second barplot of the difference in frequency for each bucket.\n",
    "        #diff_ax = fig.add_subplot(2, 1, 2)\n",
    "        enDiff = eTotal - nTotal\n",
    "        \n",
    "        has_diff_in_diff_data = (e10s_std is not None and len(e10s_std) > 0 and\n",
    "                                 none10s_std is not None and len(none10s_std) > 0)\n",
    "        if include_diff_in_diff and has_diff_in_diff_data:\n",
    "            ## Add bin differences for between e10s/non-e10s for the no-addons cohorts.\n",
    "            ## The assumption is that the difference between addons cohorts would look the same\n",
    "            ## if there is no additional effect of having addons.\n",
    "            eTotal_std = make_group_histogram(e10s_std)\n",
    "            nTotal_std = make_group_histogram(none10s_std)\n",
    "            enDiff_std = eTotal_std - nTotal_std\n",
    "            ylims = (min(enDiff.min(), enDiff_std.min()) - 0.5, max(enDiff.max(), enDiff_std.max()) + 0.5)\n",
    "            diff_ax2 = diff_ax.twinx()\n",
    "            \n",
    "            enDiff.plot(kind=\"bar\", alpha=0.5, color=\"navy\", label=\"with add-ons\", ax=diff_ax, width=width,\n",
    "                        position=1, ylim=ylims)\n",
    "            enDiff_std.plot(kind=\"bar\", alpha=0.5, color=\"gray\", label=\"no add-ons\", ax=diff_ax2, width=width,\n",
    "                        position=0, grid=False, ylim=diff_ax.get_ylim())\n",
    "\n",
    "            ## Combine legend info from both Axes.\n",
    "            diff_ax_h, diff_ax_l = diff_ax.get_legend_handles_labels()\n",
    "            diff_ax2_h, diff_ax2_l = diff_ax2.get_legend_handles_labels()\n",
    "            leg_h = diff_ax_h + diff_ax2_h\n",
    "            leg_l = diff_ax_l + diff_ax2_l\n",
    "            \n",
    "            if did_separate_plot:\n",
    "                enDiffDiff = enDiff - enDiff_std\n",
    "                enDiffDiff.plot(kind=\"bar\", alpha=0.5, color=\"maroon\", ax=diff_diff_ax, ylim=diff_ax.get_ylim())\n",
    "                diff_diff_ax.xaxis.grid(False)\n",
    "                diff_diff_ax.set_ylabel(\"Diff in freq %\")\n",
    "                diff_diff_ax.set_title(\"Diff between e10s/non diff with add-ons and e10s/non diff without\" +\n",
    "                                      \" (with add-ons higher when > 0)\")\n",
    "            \n",
    "        else:\n",
    "            if include_diff_in_diff:\n",
    "                ## We wanted to do the additional comparison, but there wasn't enough data.\n",
    "                print(\"\\nNo diff-in-diff comparison: one of the standard cohorts has no non-missing observations.\")\n",
    "            enDiff.plot(kind=\"bar\", alpha=0.5, color=\"navy\", label=\"with add-ons\", ax=diff_ax)\n",
    "            leg_h, leg_l = diff_ax.get_legend_handles_labels()\n",
    "        \n",
    "        plt.title(\"e10s/non-e10s difference (more e10s in bucket when > 0)\")\n",
    "        diff_ax.xaxis.grid(False)\n",
    "        diff_ax.set_ylabel(\"Diff in frequency %\")\n",
    "        diff_ax.legend(leg_h, leg_l, loc = 0)\n",
    "    \n",
    "    \n",
    "    # Only display at most 100 tick labels on the x axis.\n",
    "    xticklabs = plt.gca().get_xticklabels()\n",
    "    max_x_ticks = 100\n",
    "    if len(xticklabs) > max_x_ticks:\n",
    "        step_size = math.ceil(float(len(xticklabs)) / max_x_ticks)\n",
    "        for i, tl in enumerate(xticklabs):\n",
    "            if i % step_size != 0:\n",
    "                tl.set_visible(False)\n",
    "    plt.show()\n",
    "    \n",
    "    ## Compute a p-value for the chi-square distance between the groups' combined histograms.\n",
    "    pvalue = grouped_permutation_test(chi2_distance, [e10s_addons, none10s_addons], num_samples=100)\n",
    "    print(\"The probability that the distributions for {} (with add-ons) are differing by chance is {:.3f}.\"\\\n",
    "          .format(histogram, pvalue))\n",
    "\n",
    "def normalize_uptime_hour(frame):\n",
    "    \"\"\" Convert metrics to rates per hour of uptime. \"\"\"\n",
    "    frame = frame[frame[\"payload/simpleMeasurements/totalTime\"] > 60]\n",
    "    frame = 60 * 60 * frame.apply(lambda x: x / frame[\"payload/simpleMeasurements/totalTime\"]) # Metric per hour\n",
    "    frame.drop('payload/simpleMeasurements/totalTime', axis=1, inplace=True)\n",
    "    return frame\n",
    "    \n",
    "def compare_e10s_count_histograms(pings, cohort_sizes = {}, *histogram_names, **kwargs):\n",
    "    \"\"\" Read multiple count histograms from a collection of pings, and compare e10s/non-e10s for each.\n",
    "    \n",
    "        Treats count histograms as scalars for comparison purposes, without distinguishing between\n",
    "        parent and child processes. Expects a dict containing overall cohort sizes\n",
    "        for computing sample size proportions.\n",
    "    \"\"\"\n",
    "    properties = histogram_names + (\"payload/simpleMeasurements/totalTime\", \"e10s\", \"addons\")\n",
    "    frame = pd.DataFrame(get_pings_properties(pings, properties).collect())\n",
    "    \n",
    "    e10s = frame[frame[\"addons\"] & frame[\"e10s\"]]\n",
    "    e10s = normalize_uptime_hour(e10s)\n",
    "    \n",
    "    none10s = frame[frame[\"addons\"] & ~frame[\"e10s\"]]\n",
    "    none10s = normalize_uptime_hour(none10s)\n",
    "    \n",
    "    include_diff_in_diff = kwargs.get(\"include_diff_in_diff\", True)\n",
    "    if include_diff_in_diff:\n",
    "        e10s_std = normalize_uptime_hour(frame[~frame[\"addons\"] & frame[\"e10s\"]])\n",
    "        none10s_std = normalize_uptime_hour(frame[~frame[\"addons\"] & ~frame[\"e10s\"]])        \n",
    "    \n",
    "    for histogram in histogram_names:\n",
    "        if histogram not in none10s.columns:\n",
    "            continue\n",
    "        \n",
    "        ## Remove the property path from the histogram name for display purposes.\n",
    "        hist_name = hist_base_name(histogram)\n",
    "        if type(hist_name) == list:\n",
    "            ## Key was given for keyed histogram.\n",
    "            hist_str = \"{}/{}\".format(link_to_histogram(hist_name[0]), hist_name[1])\n",
    "            hist_name = hist_name[0]\n",
    "        else:\n",
    "            hist_str = hist_name\n",
    "        ## Print a header for the block of graphs, including a link to the histogram definition.\n",
    "        print_with_markdown(\"Comparison for count histogram {} (with add-ons):\".format(hist_str))\n",
    "        \n",
    "        e10s_hist = e10s[histogram].dropna()\n",
    "        non_e10s_hist = none10s[histogram].dropna()\n",
    "        \n",
    "        ## Print some information on sample sizes.\n",
    "        print(\"{} non-e10s profiles have this histogram.\".format(\n",
    "                sample_size_str(len(non_e10s_hist), cohort_sizes.get(\"addons-set2a-control\"))))\n",
    "        print(\"{} e10s profiles have this histogram.\".format(\n",
    "                sample_size_str(len(e10s_hist), cohort_sizes.get(\"addons-set2a-test\"))))\n",
    "        ## If either group has no data, nothing more to do.\n",
    "        if len(non_e10s_hist) == 0 or len(e10s_hist) == 0:\n",
    "            continue\n",
    "        \n",
    "        print(\"\")\n",
    "        compare_scalars(hist_name + \" per hour\", e10s_hist, non_e10s_hist,\n",
    "                        e10s_std[histogram].dropna() if include_diff_in_diff else None,\n",
    "                        none10s_std[histogram].dropna() if include_diff_in_diff else None)\n",
    " \n",
    "def compare_e10s_histograms(pings, cohort_sizes = {}, *histogram_names, **kwargs):\n",
    "    \"\"\" Read multiple histograms from a collection of pings, and compare e10s/non-e10s for each.\n",
    "    \n",
    "        Outputs separate comparisons for parent process, child processes, and merged histograms.\n",
    "        Expects a dict containing overall cohort sizes for computing sample\n",
    "        size proportions.\n",
    "    \"\"\"\n",
    "    ## Load histogram data from the ping set, separating parent & child processes for e10s.\n",
    "    frame = pd.DataFrame(get_pings_properties(pings, histogram_names + (\"e10s\", \"addons\") , with_processes=True)\\\n",
    "        .collect())\n",
    "    ## The addons experiment cohorts.\n",
    "    e10s_addons = frame[frame[\"addons\"] & frame[\"e10s\"]]\n",
    "    none10s_addons = frame[frame[\"addons\"] & ~frame[\"e10s\"]]\n",
    "    ## The standard experiment cohorts.\n",
    "    e10s_std = frame[~frame[\"addons\"] & frame[\"e10s\"]]\n",
    "    none10s_std = frame[~frame[\"addons\"] & ~frame[\"e10s\"]]\n",
    "    \n",
    "    for histogram in histogram_names:\n",
    "        if histogram not in none10s_addons.columns:\n",
    "            continue\n",
    "        \n",
    "        ## Remove the property path from the histogram name for display purposes.\n",
    "        hist_name = hist_base_name(histogram)\n",
    "        if type(hist_name) == list:\n",
    "            ## Key was given for keyed histogram.\n",
    "            hist_str = \"{}/{}\".format(link_to_histogram(hist_name[0]), hist_name[1])\n",
    "            hist_name = hist_name[0]\n",
    "        else:\n",
    "            hist_str = hist_name\n",
    "        ## Print a header for the block of graphs, including a link to the histogram definition.\n",
    "        print_with_markdown(\"Comparison for {} (with add-ons):\".format(hist_str))\n",
    "        \n",
    "        ## Compare the main histogram for non-e10s against each of 3 for e10s.\n",
    "        addons_hist_data = {\n",
    "            \"non_e10s\": none10s_addons[histogram],\n",
    "            \"e10s_merged\": e10s_addons[histogram],\n",
    "            \"e10s_parent\": e10s_addons[histogram + \"_parent\"],\n",
    "            \"e10s_children\": e10s_addons[histogram + \"_children\"]\n",
    "        }\n",
    "        for htype in addons_hist_data:\n",
    "            addons_hist_data[htype] = addons_hist_data[htype].dropna()\n",
    "        \n",
    "        ## Print some information on sample sizes.\n",
    "        sample_sizes = { htype: len(hdata) for htype, hdata in addons_hist_data.iteritems() }\n",
    "        print(\"{} non-e10s profiles have this histogram.\".format(\n",
    "                sample_size_str(sample_sizes[\"non_e10s\"], cohort_sizes.get(\"addons-set2a-control\"))))\n",
    "        print(\"{} e10s profiles have this histogram.\".format(\n",
    "                sample_size_str(sample_sizes[\"e10s_merged\"], cohort_sizes.get(\"addons-set2a-test\"))))\n",
    "        ## If either group has no data, nothing more to do.\n",
    "        if sample_sizes[\"non_e10s\"] == 0 or sample_sizes[\"e10s_merged\"] == 0:\n",
    "            continue\n",
    "        \n",
    "        print(\"{} e10s profiles have the parent histogram.\".format(\n",
    "                sample_size_str(sample_sizes[\"e10s_parent\"], cohort_sizes.get(\"addons-set2a-test\"))))\n",
    "        print(\"{} e10s profiles have the children histogram.\".format(\n",
    "                sample_size_str(sample_sizes[\"e10s_children\"], cohort_sizes.get(\"addons-set2a-test\"))))\n",
    "        \n",
    "        has_parent = sample_sizes[\"e10s_parent\"] > 0\n",
    "        has_children = sample_sizes[\"e10s_children\"] > 0\n",
    "        \n",
    "        non_e10s_std_hist = none10s_std[histogram].dropna()\n",
    "        \n",
    "        ## Compare merged histograms, unless e10s group has either no parents or no children.\n",
    "        if has_children and has_parent:\n",
    "            compare_histogram(hist_name + \" (e10s merged)\", \n",
    "                              addons_hist_data[\"e10s_merged\"],\n",
    "                              addons_hist_data[\"non_e10s\"],\n",
    "                              e10s_std[histogram].dropna(),\n",
    "                              non_e10s_std_hist,\n",
    "                              **kwargs)\n",
    "        \n",
    "        if has_parent:\n",
    "            compare_histogram(hist_name + \" (parent)\",\n",
    "                              addons_hist_data[\"e10s_parent\"],\n",
    "                              addons_hist_data[\"non_e10s\"],\n",
    "                              e10s_std[histogram + \"_parent\"].dropna(),\n",
    "                              non_e10s_std_hist,\n",
    "                              **kwargs)\n",
    "\n",
    "        if has_children:\n",
    "            compare_histogram(hist_name + \" (children)\",\n",
    "                              addons_hist_data[\"e10s_children\"],\n",
    "                              addons_hist_data[\"non_e10s\"],\n",
    "                              e10s_std[histogram + \"_children\"].dropna(),\n",
    "                              non_e10s_std_hist,\n",
    "                              **kwargs)\n",
    "\n",
    "def compare_scalars(metric, e10s_data, non_e10s_data, e10s_std=None, non_e10s_std=None, unit=\"units\"):\n",
    "    \"\"\" Prints info about the median difference between the groups, together with a p-value\n",
    "        for testing the difference.\n",
    "        \n",
    "        Optionally include a string indicating the units the metric is measured in.\n",
    "        If data is supplied, also print a comparison for non-addons cohorts.\n",
    "    \"\"\"\n",
    "    e10s_data = e10s_data.dropna()\n",
    "    non_e10s_data = non_e10s_data.dropna()\n",
    "    if len(e10s_data) == 0 or len(non_e10s_data) == 0:\n",
    "        print(\"Cannot run comparison: one of the groups has no non-missing observations.\")\n",
    "        return\n",
    "    \n",
    "    print(\"Comparison for {}{} (with add-ons):\\n\".format(metric, \" ({})\".format(unit) if unit != \"units\" else \"\"))\n",
    "    e10s_median = np.median(e10s_data)\n",
    "    non_e10s_median = np.median(non_e10s_data)\n",
    "    mdiff = median_diff(e10s_data, non_e10s_data)\n",
    "    print(\"- Median with e10s is {:.3g} {} {} median without e10s.\"\\\n",
    "         .format(\n",
    "            #abs(mdiff),\n",
    "            mdiff,\n",
    "            unit,\n",
    "            #\"higher than\" if mdiff >= 0 else \"lower than\"\n",
    "            \"different from\"))\n",
    "    print(\"- This is a relative difference of {:.1f}%.\".format(float(mdiff) / non_e10s_median * 100))\n",
    "    print(\"- E10s group median is {:.4g}, non-e10s group median is {:.4g}.\".format(e10s_median, non_e10s_median))\n",
    "            \n",
    "    print(\"\\nThe probability of this difference occurring purely by chance is {:.3f}.\"\\\n",
    "        .format(grouped_permutation_test(median_diff, [e10s_data, non_e10s_data], num_samples=10000)))\n",
    "    \n",
    "    if e10s_std is not None and non_e10s_std is not None:\n",
    "        ## Include a comparison between non-addon cohorts.\n",
    "        e10s_std = e10s_std.dropna()\n",
    "        non_e10s_std = non_e10s_std.dropna()\n",
    "        if len(e10s_std) > 0 and len(non_e10s_std) > 0:\n",
    "            non_e10s_std_median = np.median(non_e10s_std)\n",
    "            mdiff_std = median_diff(e10s_std, non_e10s_std)\n",
    "            print(\"\\nFor cohorts with no add-ons, median with e10s is {:.3g} {} ({:.1f}%) {} median without\"\\\n",
    "                 .format(\n",
    "                    #abs(mdiff_std),\n",
    "                    mdiff_std,\n",
    "                    unit,\n",
    "                    float(mdiff_std) / non_e10s_std_median * 100,\n",
    "                    #\"higher than\" if mdiff_std >= 0 else \"lower than\"\n",
    "                    \"different from\"))\n",
    "\n",
    "    \n",
    "def link_to_histogram(hist_name):\n",
    "    \"\"\" Create a link to the histogram definition in Markdown. \"\"\"\n",
    "    return \"[{}](https://dxr.mozilla.org/mozilla-central/search?q={}+file%3AHistograms.json&redirect=true)\"\\\n",
    "            .format(hist_name, hist_name)\n",
    "\n",
    "def hist_base_name(path_to_histogram):\n",
    "    \"\"\" Remove any path components from histogram name.\n",
    "    \n",
    "        If histogram is specified as a path in the payload, with separator '/',\n",
    "        remove everything but the last component (the actual name).\n",
    "        However, if the histogram is keyed, and specified with a key, return\n",
    "        [histname, key].\n",
    "    \"\"\"\n",
    "    path_to_histogram = path_to_histogram.rsplit(\"/\")\n",
    "    if len(path_to_histogram) > 1 and path_to_histogram[-3] == \"keyedHistograms\":\n",
    "        ## There was a keyedHistogram name and key given.\n",
    "        return path_to_histogram[-2:]\n",
    "    return path_to_histogram[-1]\n",
    "\n",
    "## Hack to render links in code output.\n",
    "from IPython.display import Markdown, display\n",
    "def print_with_markdown(md_text):\n",
    "    \"\"\" Print Markdown text so that it renders correctly in the cell output. \"\"\"\n",
    "    display(Markdown(md_text))\n",
    "\n",
    "def sample_size_str(sample_size, cohort_size=None):\n",
    "    \"\"\" Convert a sample size to a string representation, including a percentage if available. \"\"\"\n",
    "    if sample_size == 0:\n",
    "        return \"No\"\n",
    "    if cohort_size:\n",
    "        if sample_size == cohort_size:\n",
    "            return \"All\"\n",
    "        return \"{} ({:.1f}%)\".format(sample_size, float(sample_size) / cohort_size * 100)\n",
    "    return str(sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get e10s/non-e10s cohorts for the add-ons experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derived dataset is computed from profiles on Beta 50 who have e10sCohort set. It contains a single record (ping) per client, which is randomly selected from among the client's pings during the date range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# regenerated data and loaded into telemetry-test-bucket\n",
    "dataset = sqlContext.read.parquet(\n",
    "    \"s3://telemetry-parquet/e10s_experiment_view/e10s_addons_beta51_cohorts/v20161228_20170104/\")\n",
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many records are in the overall dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the cohorts, and how many clients do we have in each cohort?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time cohort_counts = dataset.groupby(\"e10sCohort\").count().collect()\n",
    "dataset_count = sum(map(lambda r: r[\"count\"], cohort_counts))\n",
    "\n",
    "def cohort_proportions(r):\n",
    "    prop = r[\"count\"] * 100.0 / dataset_count\n",
    "    return (r[\"e10sCohort\"], r[\"count\"], \"{:.2f}%\".format(prop))\n",
    "\n",
    "print(\"\\nTotal number of clients: {:,}\".format(dataset_count))\n",
    "sorted(map(cohort_proportions, cohort_counts), key = lambda r: r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ADDONS_TEST_COHORT = u'addons-set51alladdons-test'\n",
    "ADDONS_CONTROL_COHORT = u'addons-set51alladdons-control'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restrict to pings belonging to the e10s add-ons experiment. Also include the standard e10s test/control for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addons_exp_dataset = dataset.filter(\\\n",
    "\"e10sCohort in ('%s','%s', 'test', 'control')\" % (ADDONS_TEST_COHORT, ADDONS_CONTROL_COHORT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many clients are left?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addons_exp_dataset.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make sure that the pings tagged into the cohorts satisfy the basic assumptions of the experiment, as this not guaranteed. All add-ons cohort pings should have active add-ons, and e10s should be enabled if and only if the ping belongs to the test cohort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def e10s_status_check(settings, addons):\n",
    "    \"\"\" Check whether e10s is enabled, and whether there are add-ons. \"\"\"\n",
    "    e10sEnabled = json.loads(settings).get(\"e10sEnabled\")\n",
    "    active_addons = json.loads(addons).get(\"activeAddons\")\n",
    "    return Row(\n",
    "        e10s_enabled = bool(e10sEnabled), \n",
    "        has_addons = bool(active_addons)\n",
    "    )\n",
    "\n",
    "def bad_ping(cohort, settings, addons):\n",
    "    \"\"\" e10s should be enabled iff the profile is in the test cohort, and profiles should have active add-ons\n",
    "        if they are in the addons cohorts. \n",
    "    \"\"\"\n",
    "    check_data = e10s_status_check(settings, addons)\n",
    "    is_bad = cohort.endswith(\"test\") != check_data.e10s_enabled\n",
    "    if cohort.startswith(\"addons\"):\n",
    "        is_bad = is_bad or not check_data.has_addons\n",
    "    return is_bad\n",
    "\n",
    "## Add a Column to the DF with the outcome of the check.\n",
    "## This will be used to remove any bad rows after examining them.\n",
    "from pyspark.sql.types import BooleanType\n",
    "status_check_udf = fun.udf(bad_ping, BooleanType())\n",
    "addons_exp_dataset_check = addons_exp_dataset.withColumn(\"badPing\",\n",
    "    status_check_udf(addons_exp_dataset.e10sCohort, addons_exp_dataset.settings, addons_exp_dataset.addons))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are any bad pings, describe the problems and remove them from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addons_exp_dataset_bad = addons_exp_dataset_check.filter(\"badPing\")\\\n",
    "    .select(\"e10sCohort\", \"settings\", \"addons\")\\\n",
    "    .rdd\n",
    "\n",
    "has_bad = not addons_exp_dataset_bad.isEmpty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not has_bad:\n",
    "    print(\"No issues\")\n",
    "else:\n",
    "    check_counts = addons_exp_dataset_bad\\\n",
    "        .map(lambda r: (r.e10sCohort, e10s_status_check(r.settings, r.addons)))\\\n",
    "        .countByValue()\n",
    "    print(\"Issues:\")\n",
    "    for k, v in check_counts.iteritems():\n",
    "        print(\"{}: {}\".format(k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if has_bad:\n",
    "    print(\"\\nRemoving these pings from the dataset.\")\n",
    "    addons_exp_dataset = addons_exp_dataset_check.filter(\"not badPing\").drop(\"badPing\")\n",
    "    print(\"The dataset now contains {} clients\".format(addons_exp_dataset.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What add-ons are present for the addons cohorts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_active_addon_info(addons_str):\n",
    "    \"\"\" Return a list of currently enabled add-ons in the form (GUID, name, version, isSystem). \"\"\"\n",
    "    addons = json.loads(addons_str)\n",
    "    addons = addons.get(\"activeAddons\", {})\n",
    "    if not addons:\n",
    "        return []\n",
    "    return [(guid, meta.get(\"name\"), meta.get(\"isSystem\"), meta.get('version')) for guid, meta in addons.iteritems()]\n",
    "\n",
    "\n",
    "def dataset_installed_addons(data, n_top=100):\n",
    "    \"\"\" Extract add-on info from a subset of the main dataset, and generate a table of top add-ons\n",
    "        with installation counts.\n",
    "        \n",
    "        Returns a Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    data_addons = data.select(\"addons\").rdd.map(lambda row: row[\"addons\"])\n",
    "    data_addons.cache()\n",
    "    n_in_data = data_addons.count()\n",
    "    \n",
    "    ##  Get counts by add-on ID/name/isSystem value.\n",
    "    addon_counts = data_addons.flatMap(get_active_addon_info)\\\n",
    "        .map(lambda a: (a, 1))\\\n",
    "        .reduceByKey(add)\\\n",
    "        .map(lambda ((guid, name, sys, version), n): (guid, (name, sys, version, n)))\n",
    "    \n",
    "    ## Summarize using the most common name and isSystem value.\n",
    "    top_vals = addon_counts.reduceByKey(lambda a, b: a if a[-1] > b[-1] else b)\\\n",
    "        .map(lambda (guid, (name, sys, version, n)): (guid, (name, sys, version)))\n",
    "    n_installs = addon_counts.mapValues(lambda (name, sys, version, n): n)\\\n",
    "        .reduceByKey(add)\n",
    "    addon_info = top_vals.join(n_installs)\\\n",
    "        .map(lambda (guid, ((name, sys, version), n)): {\n",
    "                \"guid\": guid,\n",
    "                \"name\": name,\n",
    "                \"is_system\": sys,\n",
    "                \"version\":version,\n",
    "                \"n_installs\": n,\n",
    "                \"pct_installed\": n / n_in_data * 100\n",
    "            })\\\n",
    "        .sortBy(lambda info: info[\"n_installs\"], ascending=False)\n",
    "    \n",
    "    addon_info_coll = addon_info.collect() if not n_top else addon_info.take(n_top)\n",
    "    addon_info_table = pd.DataFrame(addon_info_coll)\n",
    "    addon_info_table = addon_info_table[[\"guid\", \"name\", \"version\",\"is_system\", \"n_installs\", \"pct_installed\"]]\n",
    "    ## Number rows from 1.\n",
    "    addon_info_table.index += 1\n",
    "    n_addons = addon_info.count()\n",
    "    data_addons.unpersist()\n",
    "    return (n_addons, addon_info_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addons_cohort_num, addons_cohort_table = dataset_installed_addons(\n",
    "    addons_exp_dataset.filter(\"e10sCohort like 'addons%'\"),\n",
    "    n_top=100)\n",
    "print(\"There were {:,} distinct add-ons installed across the addons cohort.\".format(addons_cohort_num))\n",
    "\n",
    "addons_cohort_table[\"n_installs\"] = addons_cohort_table[\"n_installs\"].map(\"{:,}\".format)\n",
    "addons_cohort_table[\"pct_installed\"] = addons_cohort_table[\"pct_installed\"].map(\"{:.2f}\".format)\n",
    "addons_cohort_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What add-ons are present in the standard (non-addons) cohorts, if any?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std_cohort_num, std_cohort_table = dataset_installed_addons(\n",
    "    addons_exp_dataset.filter(\"e10sCohort in ('test', 'control')\"),\n",
    "    n_top=100)\n",
    "print(\"There were {:,} distinct add-ons installed across the standard cohort.\".format(std_cohort_num))\n",
    "\n",
    "std_cohort_table[\"n_installs\"] = std_cohort_table[\"n_installs\"].map(\"{:,}\".format)\n",
    "std_cohort_table[\"pct_installed\"] = std_cohort_table[\"pct_installed\"].map(\"{:.2f}\".format)\n",
    "std_cohort_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Dataframe to RDD of pings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def row_2_ping(row):\n",
    "    ping = {\n",
    "        \"payload\": {\"simpleMeasurements\": json.loads(row.simpleMeasurements) if row.simpleMeasurements else {},\n",
    "                    \"histograms\": json.loads(row.histograms) if row.histograms else {},\n",
    "                    \"keyedHistograms\": json.loads(row.keyedHistograms) if row.keyedHistograms else {},\n",
    "                    \"childPayloads\": json.loads(row.childPayloads) if row.childPayloads else {},\n",
    "                    \"threadHangStats\": json.loads(row.threadHangStats)} if row.threadHangStats else {},\n",
    "       \"e10s\": True if row.e10sCohort.endswith(\"test\") else False,\n",
    "       \"addons\": True if row.e10sCohort.startswith(\"addons\") else False,\n",
    "       \"system\": json.loads(row.system),\n",
    "       \"cohort\": row.e10sCohort\n",
    "    }\n",
    "    return ping\n",
    "\n",
    "def notxp(p):\n",
    "    os = p.get(\"system\", {}).get(\"os\", {})\n",
    "    return os[\"name\"] != \"Windows_NT\" or os[\"version\"] != \"5.1\"\n",
    "\n",
    "subset = addons_exp_dataset.rdd.map(row_2_ping).filter(notxp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_gecko_activity(ping):\n",
    "    uptime = ping[\"payload\"].get(\"simpleMeasurements\", {}).get(\"totalTime\", -1) / 60\n",
    "    if uptime <= 0:\n",
    "        return ping\n",
    "\n",
    "    def get_hangs_per_minute(threads, thread_name, uptime):\n",
    "        for thread in threads:\n",
    "            if thread[\"name\"] == thread_name:\n",
    "                activity = thread[\"activity\"][\"values\"]\n",
    "                if activity:\n",
    "                    histogram = pd.Series(activity.values(), index=map(int, activity.keys())).sort_index()\n",
    "                    # 255 is upper bound for 128-255ms bucket.\n",
    "                    return histogram[histogram.index >= 255].sum() / uptime\n",
    "        return None\n",
    "\n",
    "    threads = ping[\"payload\"].get(\"threadHangStats\", {})\n",
    "    ping[\"parent_hangs_per_minute\"] = get_hangs_per_minute(threads, \"Gecko\", uptime)\n",
    "\n",
    "    child_payloads = ping[\"payload\"].get(\"childPayloads\", [])\n",
    "    child_hangs_per_minute = []\n",
    "    for payload in child_payloads:\n",
    "        child_uptime = payload.get(\"simpleMeasurements\", {}).get(\"totalTime\", -1) / 60\n",
    "        if child_uptime <= 0:\n",
    "            continue\n",
    "        child_threads = payload.get(\"threadHangStats\", {})\n",
    "        child_hangs = get_hangs_per_minute(child_threads, \"Gecko_Child\", child_uptime)\n",
    "        if child_hangs:\n",
    "            child_hangs_per_minute.append(child_hangs)\n",
    "\n",
    "    if len(child_hangs_per_minute) > 0:\n",
    "        ping[\"child_hangs_per_minute\"] = sum(child_hangs_per_minute) / len(child_hangs_per_minute)\n",
    "\n",
    "    return ping\n",
    "\n",
    "subset = subset.map(add_gecko_activity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, how many clients are left in each cohort? Key first by cohort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subset = subset.map(lambda r: (r[\"cohort\"], r))\n",
    "\n",
    "cohort_sizes = subset.countByKey()\n",
    "cohort_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We include the standard e10s cohorts to provide an additional comparison to the addon cohorts. If we see an e10s-related difference for profiles with add-ons, we want to see whether the difference is specific to having add-ons, or whether it occurs regardless.\n",
    "\n",
    "Since the addon cohorts are much smaller than the standard ones, we draw samples from the standard ones to make them approximately the same size.\n",
    "\n",
    "NOTE: **MPC=False should be blocked (see [bug](https://bugzilla.mozilla.org/show_bug.cgi?id=1329695)), temporary fix:**\n",
    "In Beta 51, we have a much larger cohort size for addons since we do not only take MPC=True, so we will sample 25% of the cohort to approximately match previous cohort sizes. This is necessary to continue the analysis due to memory contraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_prop_test = cohort_sizes[ADDONS_TEST_COHORT] / cohort_sizes[\"test\"]\n",
    "target_prop_control = cohort_sizes[ADDONS_CONTROL_COHORT] / cohort_sizes[\"control\"]\n",
    "sampling_props = {\n",
    "    ADDONS_TEST_COHORT: .25,\n",
    "    ADDONS_CONTROL_COHORT: .25,\n",
    "    u\"test\": target_prop_test * .25,\n",
    "    u\"control\": target_prop_control * .25    \n",
    "}\n",
    "subset = subset.sampleByKey(False, sampling_props)\\\n",
    "    .persist(StorageLevel.MEMORY_AND_DISK_SER)\n",
    "    \n",
    "print 'Sampling the following proportions from each group:'\n",
    "sampling_props\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the final cohort sizes, and wrap them into the histogram comparison functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e10s_addon_cohort_sizes = subset.countByKey()\n",
    "\n",
    "## Remove the cohort label key from the dataset.\n",
    "subset = subset.map(lambda r: r[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Final cohort sizes:\")\n",
    "print(\" - e10s (with add-ons): {}\".format(e10s_addon_cohort_sizes[ADDONS_TEST_COHORT]))\n",
    "print(\" - non-e10s (with add-ons): {}\".format(e10s_addon_cohort_sizes[ADDONS_CONTROL_COHORT]))\n",
    "print(\" - e10s (no add-ons): {}\".format(e10s_addon_cohort_sizes[\"test\"]))\n",
    "print(\" - non-e10s (no add-ons): {}\".format(e10s_addon_cohort_sizes[\"control\"]))\n",
    "\n",
    "def compare_histograms(pings, *histogram_names, **kwargs):\n",
    "    return compare_e10s_histograms(pings, e10s_addon_cohort_sizes, *histogram_names, **kwargs)\n",
    "    \n",
    "def compare_count_histograms(pings, *histogram_names, **kwargs):\n",
    "    return compare_e10s_count_histograms(pings, e10s_addon_cohort_sizes, *histogram_names, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Jank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset,  \n",
    "                   \"payload/histograms/GC_MAX_PAUSE_MS\",\n",
    "                   \"payload/histograms/CYCLE_COLLECTOR_MAX_PAUSE\",\n",
    "                   \"payload/histograms/INPUT_EVENT_RESPONSE_MS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Page load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset, \"payload/histograms/FX_PAGE_LOAD_MS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Startup/shutdown time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simple = pd.DataFrame(get_pings_properties(subset, [\n",
    "    \"payload/simpleMeasurements/firstPaint\",\n",
    "    \"payload/simpleMeasurements/sessionRestored\",\n",
    "    \"payload/simpleMeasurements/shutdownDuration\",\n",
    "    \"e10s\",\n",
    "    \"addons\"]).collect())\n",
    "\n",
    "eSimple = simple[simple[\"addons\"] & simple[\"e10s\"]]\n",
    "nSimple = simple[simple[\"addons\"] & ~simple[\"e10s\"]]\n",
    "eSimple_std = simple[~simple[\"addons\"] & simple[\"e10s\"]]\n",
    "nSimple_std = simple[~simple[\"addons\"] & ~simple[\"e10s\"]]\n",
    "\n",
    "len(eSimple), len(nSimple), len(eSimple_std), len(nSimple_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_scalars(\"firstPaint time\",\n",
    "                eSimple[\"payload/simpleMeasurements/firstPaint\"],\n",
    "                nSimple[\"payload/simpleMeasurements/firstPaint\"],\n",
    "                eSimple_std[\"payload/simpleMeasurements/firstPaint\"],\n",
    "                nSimple_std[\"payload/simpleMeasurements/firstPaint\"],\n",
    "                \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_scalars(\"sessionRestored time\",\n",
    "                eSimple[\"payload/simpleMeasurements/sessionRestored\"],\n",
    "                nSimple[\"payload/simpleMeasurements/sessionRestored\"],\n",
    "                eSimple_std[\"payload/simpleMeasurements/sessionRestored\"],\n",
    "                nSimple_std[\"payload/simpleMeasurements/sessionRestored\"],\n",
    "               \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_scalars(\"shutdownDuration time\",\n",
    "                eSimple[\"payload/simpleMeasurements/shutdownDuration\"],\n",
    "                nSimple[\"payload/simpleMeasurements/shutdownDuration\"],\n",
    "                eSimple_std[\"payload/simpleMeasurements/shutdownDuration\"],\n",
    "                nSimple_std[\"payload/simpleMeasurements/shutdownDuration\"],\n",
    "               \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Scrolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset, \"payload/histograms/FX_REFRESH_DRIVER_SYNC_SCROLL_FRAME_DELAY_MS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Plugin jank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plugin jank histograms are keyed by plugin. We find the most common plugin across all three histograms, and make the comparisons for that plugin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plugin_hist = [\"BLOCKED_ON_PLUGIN_MODULE_INIT_MS\",\n",
    "               \"BLOCKED_ON_PLUGIN_INSTANCE_INIT_MS\",\n",
    "               \"BLOCKED_ON_PLUGIN_INSTANCE_DESTROY_MS\"]\n",
    "\n",
    "def get_hist_plugins(ping):\n",
    "    \"\"\" Find the keys used across all plugin histograms. \"\"\"\n",
    "    khist = ping.get(\"payload\", {}).get(\"keyedHistograms\", {})\n",
    "    plugin_keys = []\n",
    "    for h in plugin_hist:\n",
    "        if h in khist:\n",
    "            plugin_keys += map(lambda k: (h, k), khist[h].keys())\n",
    "    return plugin_keys\n",
    "        \n",
    "plugin_hist_counts = subset.flatMap(get_hist_plugins).countByValue()\n",
    "## Find the most commonly occurring plugin for each histogram.\n",
    "top_plugins = {}\n",
    "for h in plugin_hist:\n",
    "    pl_for_hist = [(pl, n) for ((hist, pl), n) in plugin_hist_counts.iteritems()\n",
    "                       if hist == h]\n",
    "    top_plugins[h] = sorted(pl_for_hist, key=lambda (pl, n): n, reverse=True)[0]\n",
    "\n",
    "for hist, (pl, n) in top_plugins.iteritems():\n",
    "    print(\"Top plugin for {}: '{}'\".format(hist, pl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_plugin = sorted(top_plugins.items(), key=lambda (pl, n): n, reverse=True)[0]\n",
    "top_plugin = top_plugin[1][0]\n",
    "print(\"Comparing plugin jank for '{}' (overall top plugin)\".format(top_plugin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset,\n",
    "                   \"payload/keyedHistograms/BLOCKED_ON_PLUGIN_MODULE_INIT_MS/{}\".format(top_plugin),\n",
    "                   \"payload/keyedHistograms/BLOCKED_ON_PLUGIN_INSTANCE_INIT_MS/{}\".format(top_plugin),\n",
    "                   \"payload/keyedHistograms/BLOCKED_ON_PLUGIN_INSTANCE_DESTROY_MS/{}\".format(top_plugin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 Memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset,\n",
    "                   \"payload/histograms/MEMORY_TOTAL\",\n",
    "                   \"payload/histograms/MEMORY_VSIZE_MAX_CONTIGUOUS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9 UI Smoothness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__: `FX_TAB_SWITCH_TOTAL_MS` was renamed to `FX_TAB_SWITCH_TOTAL_E10S_MS` for e10s profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_hist(ping):\n",
    "    \"\"\" Rename the histogram for e10s profiles. \"\"\"\n",
    "    hist = ping.get(\"payload\", {}).get(\"histograms\", {})\n",
    "    if \"FX_TAB_SWITCH_TOTAL_E10S_MS\" in hist and \"FX_TAB_SWITCH_TOTAL_MS\" not in hist:\n",
    "        hist[\"FX_TAB_SWITCH_TOTAL_MS\"] = hist[\"FX_TAB_SWITCH_TOTAL_E10S_MS\"]\n",
    "    return ping\n",
    "\n",
    "subset_fixed = subset.map(fix_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset_fixed, \"payload/histograms/FX_TAB_SWITCH_TOTAL_MS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.11 Slow Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_count_histograms(subset, \"payload/histograms/SLOW_SCRIPT_PAGE_COUNT\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}